{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4300b8",
   "metadata": {},
   "source": [
    "- VTT ëª¨ë¸ì— ë§ëŠ” í™˜ê²½ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•˜ì—¬ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83505a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T06:01:52.415481Z",
     "start_time": "2024-06-09T06:01:50.840036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iai3/Desktop/Bongjun/RTM/drystrip_4ì°¨/VTT_entire_wafer/src\n",
      "Python version:[3.9.21 (main, Dec 11 2024, 16:24:11) \n",
      "[GCC 11.2.0]].\n",
      "PyTorch version:[2.7.0+cu118].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "%cd ../src\n",
    "import os  # ìš´ì˜ ì²´ì œì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ëª¨ë“ˆ\n",
    "import sys  # ì‹œìŠ¤í…œ íŠ¹ì • íŒŒë¼ë¯¸í„°ì™€ í•¨ìˆ˜ë¥¼ ìœ„í•œ ëª¨ë“ˆ\n",
    "import random  # ë‚œìˆ˜ ìƒì„±ê¸°ë¥¼ ìœ„í•œ ëª¨ë“ˆ\n",
    "from tqdm import tqdm # ì§„í–‰ë¥ ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ëª¨ë“ˆ \n",
    "import warnings  # ê²½ê³  ë©”ì‹œì§€ë¥¼ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ\n",
    "warnings.filterwarnings(\"ignore\")  # ê²½ê³  ë©”ì‹œì§€ë¥¼ ë¬´ì‹œí•˜ë„ë¡ ì„¤ì •\n",
    "\n",
    "import numpy as np # ë‹¤ì°¨ì› ë°°ì—´ê³¼ ì—°ì‚°ì„ ë‹¤ë£¨ëŠ” ëª¨ë“ˆ\n",
    "import pandas as pd  # ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from sklearn.preprocessing import MinMaxScaler  # ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ìŠ¤ì¼€ì¼ë§ ëª¨ë“ˆ\n",
    "\n",
    "# ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import matplotlib.pyplot as plt  \n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors as mcl\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "# ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ ì¸ë¼ì¸ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ í‘œì‹œ\n",
    "%matplotlib inline\n",
    "\n",
    "from easydict import EasyDict  # ë”•ì…”ë„ˆë¦¬ì˜ ì†ì„±ì„ ì  í‘œê¸°ë²•ìœ¼ë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ëª¨ë“ˆ\n",
    "from omegaconf import OmegaConf  # ì„¤ì • íŒŒì¼ ê´€ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ\n",
    "\n",
    "import torch  # ë”¥ëŸ¬ë‹ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import h5py # ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ ëª¨ë“ˆ\n",
    "\n",
    "from utils.utils import set_seed, version_build  # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "from data_provider.waferdataset import get_dataloader  # ë°ì´í„° ë¡œë” í•¨ìˆ˜\n",
    "from model import build_model  # ëª¨ë¸ ë¹Œë“œ í•¨ìˆ˜\n",
    "from utils.utils import load_model # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë” í•¨ìˆ˜\n",
    "\n",
    "\n",
    "# torch ë²„ì „ ë° ë””ë°”ì´ìŠ¤ë¥¼ í™•ì¸\n",
    "print(\"Python version:[%s].\" % (sys.version))\n",
    "print(\"PyTorch version:[%s].\" % (torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:[%s].\" % (device))  # GPUë¥¼ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° 'cuda:0'ê°€ ì¶œë ¥ë˜ë©´ GPUë¥¼ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15eff85",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì— í•„ìš”í•œ argumentë“¤ì„ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc84ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T06:01:53.052003Z",
     "start_time": "2024-06-09T06:01:53.043970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: ./\n",
      "log_dir: ./logs\n",
      "workers: 8\n",
      "vtt_all_step:\n",
      "  train_dir: ../../data/all_step/train\n",
      "  test_dir: ../../data/all_step/test\n",
      "SMD:\n",
      "  train_dir: ../data/ServerMachineDataset/train\n",
      "  test_dir: ../data/ServerMachineDataset/test\n",
      "  test_label_dir: ../data/ServerMachineDataset/test_label\n",
      "  interpretation_label_dir: ../data/ServerMachineDataset/interpretation_label\n",
      "scale: standard\n",
      "loader_params:\n",
      "  batch_size: 32\n",
      "  shuffle: false\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  use_val: false\n",
      "VTTSAT:\n",
      "  hidden_size: 128\n",
      "  n_layer: 3\n",
      "  n_head: 4\n",
      "  resid_pdrop: 0.1\n",
      "  attn_pdrop: 0.1\n",
      "  time_emb: 4\n",
      "  optim: adamw\n",
      "  lr: 0.0001\n",
      "  lradj: type1\n",
      "  window_size: 350\n",
      "  feature_num: 12\n",
      "VTTPAT:\n",
      "  hidden_size: 128\n",
      "  n_layer: 3\n",
      "  n_head: 4\n",
      "  resid_pdrop: 0.1\n",
      "  attn_pdrop: 0.1\n",
      "  time_emb: 4\n",
      "  optim: adamw\n",
      "  lr: 0.0001\n",
      "  lradj: type1\n",
      "  window_size: 30\n",
      "  feature_num: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì • ì¸ìë“¤ì„ ì •ì˜\n",
    "args = EasyDict({\n",
    "    # for dataloader \n",
    "    'dataname': 'vtt_all_step',\n",
    "    'subdataname': None,\n",
    "    'window_size': 350,\n",
    "    'slide_size': 1,\n",
    "\n",
    "    # for training\n",
    "    'train': True,\n",
    "    'test': True,\n",
    "    'resume': None,\n",
    "    'model': 'VTTSAT',\n",
    "\n",
    "    # for setting\n",
    "    'seed': 72,\n",
    "    'use_gpu':True,\n",
    "    'gpu': 0,\n",
    "    'use_multi_gpu': False,\n",
    "    'devices': '0',\n",
    "    'configure': './config.yaml',\n",
    "    'batch_size': 16\n",
    "})\n",
    "\n",
    "# êµ¬ì„± íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "with open(args.configure) as f:\n",
    "    config = OmegaConf.load(f)\n",
    "\n",
    "# ë¡œë“œëœ êµ¬ì„± ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(OmegaConf.to_yaml(config, resolve=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¡œê·¸ ë””ë ‰í† ë¦¬ì™€ ì €ì¥ ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •\n",
    "logdir = os.path.join(config.log_dir, f'{args.dataname}/{args.model}')\n",
    "savedir = version_build(logdir=logdir, is_train=args.train, resume=args.resume)\n",
    "\n",
    "# GPU ì‚¬ìš© ì„¤ì •ì„ êµ¬ì„±\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    # GPU ë””ë°”ì´ìŠ¤ ëª©ë¡ì„ ì„¤ì •\n",
    "    args.devices = args.devices.replace(' ', '')\n",
    "    args.device_ids = list(map(int, args.devices.split(',')))\n",
    "    args.gpu = args.device_ids[0]  # ì²« ë²ˆì§¸ GPUë¥¼ ê¸°ë³¸ GPUë¡œ ì„¤ì •\n",
    "\n",
    "# ëœë¤ ì‹œë“œë¥¼ ì„¤ì •\n",
    "set_seed(args.seed)\n",
    "\n",
    "# ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •\n",
    "model_params = config[args.model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190023db",
   "metadata": {},
   "source": [
    "### Inference ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f60e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inference_result(h5_path):\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        preds = f['pred'][:]\n",
    "        actuals = f['actual'][:]\n",
    "        lotids = f['lotid'][:].astype(str)\n",
    "        wafer_numbers = f['wafer_number'][:].astype(str)\n",
    "        step_nums = f['step_num'][:]\n",
    "        masks = f['mask'][:]\n",
    "        dist_per_feature = f['dist_per_window_per_features'][:] if 'dist_per_window_per_features' in f else None\n",
    "\n",
    "    return preds, actuals, dist_per_feature, lotids, wafer_numbers, step_nums, masks\n",
    "\n",
    "# main.py --test ë¡œ ì‹¤í–‰ í›„, ì¶”ì¶œë˜ëŠ” íŒŒì¼ í•„ìš” (inference_result_with_metadata.h5)\n",
    "h5_path = './logs/vtt_all_step/VTTSAT/version5/inference_result_with_metadata.h5'\n",
    "preds, actuals, dist_per_feature, lotids, wafer_numbers, step_nums, masks = load_inference_result(h5_path)\n",
    "\n",
    "masks = masks.reshape(16808, 350)\n",
    "\n",
    "feature_names = ['APC_Position', 'APC_Pressure', 'Gas1_Monitor', 'Gas6_Monitor', 'Mat_Irms', 'Mat_Phase','Mat_Vrms',\n",
    "                      'Mat_VC1_Position', 'Mat_VC2_Position', 'SourcePwr_Read', 'Temp', 'Wall_Temp_Monitor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f6f588",
   "metadata": {},
   "source": [
    "### Inference ê²°ê³¼ë¥¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_overlay_all_wafers_subplots(\n",
    "    preds, actuals, lotids, wafer_numbers, feature_names, masks,\n",
    "    output_path='overlay_all_wafers_subplots.png', num_wafer_to_plot=1000, seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    12ê°œ ì„¼ì„œë¥¼ (3,4) subplotìœ¼ë¡œ ì‹œê°í™”. ê° subplotì—ëŠ” ì—¬ëŸ¬ ì›¨ì´í¼ê°€ ê²¹ì³ì ¸ ìˆìŒ.\n",
    "    (ì›¨ì´í¼ í•˜ë‚˜ë‹¹ ì‹œê³„ì—´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ìƒ˜í”Œë¡œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ì— ë§ê²Œ ìˆ˜ì •ë¨)\n",
    "    \"\"\"\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "    unique_wafer_ids = np.unique(unique_ids)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    selected_indices = np.random.choice(len(unique_ids), size=min(num_wafer_to_plot, len(unique_ids)), replace=False)\n",
    "\n",
    "    T = preds.shape[1]\n",
    "    D = preds.shape[2]\n",
    "\n",
    "    # ì‹œê°í™”\n",
    "    n_rows, n_cols = 3, 4\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows), sharex=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for d in range(D):\n",
    "        ax = axes[d]\n",
    "\n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            actual_seq = actuals[idx, :, d]\n",
    "            pred_seq = preds[idx, :, d]\n",
    "            \n",
    "            mask_seq = masks[idx]\n",
    "            time_indices = np.where(mask_seq ==1)[0]\n",
    "            actual_seq = actual_seq[time_indices]\n",
    "            pred_seq = pred_seq[time_indices]\n",
    "\n",
    "            label_actual = 'Actual' if i == 0 else None\n",
    "            label_pred = 'Predicted' if i == 0 else None\n",
    "\n",
    "            ax.plot(actual_seq, color='blue', alpha=0.2, linewidth=0.8, label=label_actual, zorder=0)\n",
    "            ax.plot(pred_seq, color='magenta', alpha=0.2, linewidth=0.8, label=label_pred, zorder=1)\n",
    "\n",
    "        ax.set_title(feature_names[d], fontsize=10, fontweight='bold')\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        # ax.grid(True, linestyle='-', linewidth=1.0, color='gray', alpha=0.4)\n",
    "\n",
    "        if d == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "\n",
    "    for j in range(D, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.suptitle(f'Overlay of {len(selected_indices)} Wafers per Sensor', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_overlay_all_wafers_subplots(\n",
    "    preds=preds,\n",
    "    actuals=actuals,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    feature_names=feature_names,\n",
    "    masks=masks,\n",
    "    output_path='./logs/vtt_all_step/VTTSAT/version5/plots/overlay_all_wafers_subplots.png',\n",
    "    num_wafer_to_plot=16808\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265dda5",
   "metadata": {},
   "source": [
    "### ì›¨ì´í¼ ë‹¨ìœ„ë¡œ recipe step êµ¬ë¶„í•˜ì—¬ VTT score ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vtt_score_per_stepnum(preds, actuals, masks, lotids, wafer_numbers, step_nums, feature_names):\n",
    "    \"\"\"\n",
    "    step_numë³„ë¡œ VTT scoreë¥¼ ê³„ì‚°í•˜ê³  í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ì •ë¦¬ (ì „ì²´ ì‹œê³„ì—´ 1ê°œ per wafer)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: columns = [step, unique_id, sensor1, ..., sensorN]\n",
    "    \"\"\"\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "    step_nums = np.array(step_nums)\n",
    "\n",
    "    D = preds.shape[2]\n",
    "    result_records = []\n",
    "\n",
    "    for step in sorted(np.unique(step_nums)):\n",
    "        # ğŸ”¹ í•´ë‹¹ stepë§Œ ì¶”ì¶œ\n",
    "        step_mask = step_nums == step\n",
    "        step_preds = preds[step_mask]\n",
    "        step_actuals = actuals[step_mask]\n",
    "        step_masks = masks[step_mask]\n",
    "        step_ids = unique_ids[step_mask]\n",
    "\n",
    "        for i, uid in enumerate(step_ids):\n",
    "            pred = step_preds[i]        # (T, D)\n",
    "            actual = step_actuals[i]    # (T, D)\n",
    "            mask = step_masks[i]        # (T,)\n",
    "\n",
    "            valid_idx = mask == 1\n",
    "            if not np.any(valid_idx):\n",
    "                continue\n",
    "\n",
    "            mae_per_feature = -np.sum(np.abs(pred[valid_idx] - actual[valid_idx]), axis=0)  # (D,)\n",
    "            record = {'step': int(step), 'unique_id': uid}\n",
    "            record.update({feature_names[d]: mae_per_feature[d] for d in range(D)})\n",
    "            result_records.append(record)\n",
    "\n",
    "    return pd.DataFrame.from_records(result_records)\n",
    "\n",
    "\n",
    "vtt_stepwise_scores_df = compute_vtt_score_per_stepnum(\n",
    "    preds=preds,\n",
    "    actuals=actuals,\n",
    "    masks=masks,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    step_nums=step_nums,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "vtt_stepwise_scores_df.to_csv('./logs/vtt_all_step/VTTSAT/version5/vtt_scores_per_wafer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3364c",
   "metadata": {},
   "source": [
    "### recipe step êµ¬ë¶„í•˜ì—¬ VTT score ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vtt_score_all_wafer(preds, actuals, masks, lotids, wafer_numbers, feature_names):\n",
    "    \"\"\"\n",
    "    VTT score(MAE, masking ì ìš©)ë¥¼ ì›¨ì´í¼ ë‹¨ìœ„ë¡œ ê³„ì‚°\n",
    "    step_num êµ¬ë¶„ ì—†ì´ ì „ì²´ì— ëŒ€í•´ ê³„ì‚°\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: columns = [unique_id, sensor1, ..., sensorN]\n",
    "    \"\"\"\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "\n",
    "    D = preds.shape[2]\n",
    "    result_records = []\n",
    "\n",
    "    for i, uid in enumerate(unique_ids):\n",
    "        pred = preds[i]        # (T, D)\n",
    "        actual = actuals[i]    # (T, D)\n",
    "        mask = masks[i]        # (T,)\n",
    "\n",
    "        valid_idx = mask == 1\n",
    "        if not np.any(valid_idx):\n",
    "            continue\n",
    "\n",
    "        mae_per_feature = -np.sum(np.abs(pred[valid_idx] - actual[valid_idx]), axis=0)  # (D,)\n",
    "        record = {'unique_id': uid}\n",
    "        record.update({feature_names[d]: mae_per_feature[d] for d in range(D)})\n",
    "        result_records.append(record)\n",
    "\n",
    "    return pd.DataFrame.from_records(result_records)\n",
    "\n",
    "\n",
    "vtt_all_scores_df = compute_vtt_score_all_wafer(\n",
    "    preds=preds,\n",
    "    actuals=actuals,\n",
    "    masks=masks,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "vtt_all_scores_df.to_csv('./logs/vtt_all_step/VTTSAT/version5/vtt_scores_per_wafer_allstep.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac25c1f",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ code ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae052b",
   "metadata": {},
   "source": [
    "- ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caaf032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "modelpath:  ./logs/vtt_all_step/VTTSAT/version5/1675.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.resume = 5\n",
    "model = build_model(args, model_params, savedir)\n",
    "weights, _, _, _ = load_model(resume=args.resume,\n",
    "                              logdir=savedir)\n",
    "model.model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e619c48",
   "metadata": {},
   "source": [
    "### vtt score highest/lowest ê°ê° 10ê°œ ì”© ì›¨ì´í¼ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bottom_wafers_per_sensor(score_df, top_k=10, draw_plot=True, save_dir=None):\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    sensor_columns = [col for col in score_df.columns if col not in ['step', 'unique_id']]\n",
    "    result = {}\n",
    "    result_rows = []\n",
    "\n",
    "    for sensor in sensor_columns:\n",
    "        df_sorted = score_df[['unique_id', sensor]].sort_values(by=sensor)\n",
    "        bottom_rows = df_sorted.head(top_k)\n",
    "        top_rows = df_sorted.tail(top_k)\n",
    "\n",
    "        bottom_ids = bottom_rows['unique_id'].tolist()\n",
    "        top_ids = top_rows['unique_id'].tolist()\n",
    "\n",
    "        result[sensor] = {\n",
    "            'bottom': bottom_ids,\n",
    "            'top': top_ids,\n",
    "        }\n",
    "\n",
    "        # ğŸ”´ bottom k ì¶”ê°€\n",
    "        for i in range(len(bottom_rows)):\n",
    "            result_rows.append({\n",
    "                'sensor': sensor,\n",
    "                'rank_type': 'bottom',\n",
    "                'unique_id': bottom_rows.iloc[i]['unique_id'],\n",
    "                'score': bottom_rows.iloc[i][sensor]\n",
    "            })\n",
    "\n",
    "        # ğŸ”µ top k ì¶”ê°€\n",
    "        for i in range(len(top_rows)):\n",
    "            result_rows.append({\n",
    "                'sensor': sensor,\n",
    "                'rank_type': 'top',\n",
    "                'unique_id': top_rows.iloc[i]['unique_id'],\n",
    "                'score': top_rows.iloc[i][sensor]\n",
    "            })\n",
    "\n",
    "        if draw_plot:\n",
    "            plt.figure(figsize=(6, 2.5))\n",
    "\n",
    "            others_mask = ~score_df['unique_id'].isin(top_ids + bottom_ids)\n",
    "            sns.stripplot(x=score_df[others_mask][sensor], color='gray', size=2.5, jitter=0.25, label='others')\n",
    "            sns.stripplot(x=bottom_rows[sensor], color='red', size=3, jitter=0.25, label='Lowest 10')\n",
    "            sns.stripplot(x=top_rows[sensor], color='blue', size=3, jitter=0.25, label='Highest 10')\n",
    "\n",
    "\n",
    "            plt.title(sensor)\n",
    "            plt.xlabel(\"VTT Score\")\n",
    "            plt.yticks([])\n",
    "            plt.legend(loc='upper right', fontsize=8)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save_dir:\n",
    "                plt.savefig(f\"{save_dir}/{sensor}_score_dist.png\", dpi=150)\n",
    "            else:\n",
    "                plt.show()\n",
    "\n",
    "    if save_dir:\n",
    "        df_result = pd.DataFrame(result_rows)\n",
    "        df_result.to_csv(os.path.join(save_dir, 'highest_lowest_results.csv'), index=False)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "top_bottom_ids_per_sensor = get_top_bottom_wafers_per_sensor(\n",
    "    vtt_all_scores_df,\n",
    "    top_k=10,\n",
    "    draw_plot=True,\n",
    "    save_dir=\"./logs/vtt_all_step/VTTSAT/version5/plots/score_dist\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9bb2bd",
   "metadata": {},
   "source": [
    "### reference, highest, lowest ì‹¤ì œê°’ ì‹œê³„ì—´ plot ê·¸ë¦¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_FG_ch1 = pd.read_parquet(\"drystrip_dataset/bigger_train_df.parquet\")\n",
    "interested_sensors = ['APC_Position', 'APC_Pressure', 'Gas1_Monitor', 'Gas6_Monitor', 'Mat_Irms', 'Mat_Phase','Mat_Vrms',\n",
    "                      'Mat_VC1_Position', 'Mat_VC2_Position', 'SourcePwr_Read', 'Temp', 'Wall_Temp_Monitor']\n",
    "\n",
    "filterd_df = pd.concat([P_FG_ch1[['time', 'lotid', 'wafer_number', 'Recipe_Step_Num']],P_FG_ch1[interested_sensors]], axis=1)\n",
    "filterd_df = filterd_df.sort_values(by=[\"lotid\", \"wafer_number\", \"time\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11614ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = list(filterd_df.groupby(['lotid', 'wafer_number'])) \n",
    "normal_groups = [group for group in grouped]\n",
    "train_df = pd.concat([group[1] for group in normal_groups])\n",
    "train_df_test = train_df.drop(columns='time')\n",
    "train_df_test\n",
    "train_df.groupby(['lotid','wafer_number','Recipe_Step_Num'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_data_combined = train_df.iloc[:,4:]\n",
    "train_scaled = scaler.fit_transform(train_data_combined)\n",
    "train_scaled = pd.concat([train_df.iloc[:,:4], pd.DataFrame(train_scaled, columns=interested_sensors)], axis=1)\n",
    "train_scaled = train_scaled.drop(columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263bd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_lowest_bottom_actuals_with_reference(\n",
    "    actuals, lotids, wafer_numbers, feature_names,\n",
    "    highest_lowest_df, reference_df,\n",
    "    mask=None,\n",
    "    output_dir=\"top_bottom_overlay_plots\",\n",
    "    ref_max_count=100\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "\n",
    "    D = actuals.shape[2]\n",
    "    highest_lowest_df = highest_lowest_df.copy()\n",
    "\n",
    "    for sensor in highest_lowest_df['sensor'].unique():\n",
    "        if sensor not in feature_names:\n",
    "            continue\n",
    "\n",
    "        sensor_idx = feature_names.index(sensor)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        ax.set_title(f\"{sensor} | Lowest vs Highest actuals\", fontsize=13)\n",
    "\n",
    "        # reference\n",
    "        if reference_df is not None and sensor in reference_df.columns:\n",
    "            ref_grouped = reference_df.groupby(['lotid', 'wafer_number'])\n",
    "            ref_keys = random.sample(list(ref_grouped.groups.keys()), min(ref_max_count, len(ref_grouped)))\n",
    "            for key in ref_keys:\n",
    "                ref_series = ref_grouped.get_group(key).reset_index(drop=True)[sensor].values\n",
    "                ax.plot(ref_series, color='#999999', alpha=1.0, linewidth=1.0,\n",
    "                        label='Reference' if key == ref_keys[0] else None)\n",
    "\n",
    "        # top 10\n",
    "        top_ids = highest_lowest_df[(highest_lowest_df['sensor'] == sensor) & (highest_lowest_df['rank_type'] == 'top')]['unique_id']\n",
    "        for i, uid in enumerate(top_ids):\n",
    "            idxs = np.where(unique_ids == uid)[0]\n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            idx = idxs[0]\n",
    "\n",
    "            if mask is not None:\n",
    "                valid = mask[idx] == 1\n",
    "                actual_seq = actuals[idx, valid, sensor_idx]\n",
    "            else:\n",
    "                actual_seq = actuals[idx, :, sensor_idx]\n",
    "\n",
    "            ax.plot(actual_seq, color='blue', alpha=0.6, linewidth=0.8,\n",
    "                    label='Highest 10 Actual' if i == 0 else None)\n",
    "\n",
    "        # bottom 10\n",
    "        bottom_ids = highest_lowest_df[(highest_lowest_df['sensor'] == sensor) & (highest_lowest_df['rank_type'] == 'bottom')]['unique_id']\n",
    "        for i, uid in enumerate(bottom_ids):\n",
    "            idxs = np.where(unique_ids == uid)[0]\n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            idx = idxs[0]\n",
    "\n",
    "            if mask is not None:\n",
    "                valid = mask[idx] == 1\n",
    "                actual_seq = actuals[idx, valid, sensor_idx]\n",
    "            else:\n",
    "                actual_seq = actuals[idx, :, sensor_idx]\n",
    "\n",
    "            ax.plot(actual_seq, color='red', alpha=0.6, linewidth=0.8,\n",
    "                    label='Lowest 10 Actual' if i == 0 else None)\n",
    "\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Sensor Value')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        save_path = os.path.join(output_dir, f'{sensor}_highest_lowest_actual_overlay.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    return f\"âœ… ì €ì¥ ì™„ë£Œ: {output_dir}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_lowest_df = pd.read_csv('./logs/vtt_all_step/VTTSAT/version5/plots/score_dist/highest_lowest_results.csv')\n",
    "\n",
    "highest_lowest_bottom_actuals_with_reference(\n",
    "    actuals=actuals,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    feature_names=feature_names,\n",
    "    highest_lowest_df=highest_lowest_df,\n",
    "    reference_df=train_scaled,\n",
    "    mask=masks,\n",
    "    output_dir=\"./logs/vtt_all_step/VTTSAT/version5/plots/highest_lowest_overlay\",\n",
    "    ref_max_count=1163\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ab633",
   "metadata": {},
   "source": [
    "### ê° ì„¼ì„œ ë³„ vtt score ê°€ì¥ ë†’ì€ ì›¨ì´í¼, ê°€ì¥ ë‚®ì€ ì›¨ì´í¼ì— ëŒ€í•œ ì‹œê³„ì—´ ì‹œê°í™”\n",
    "### customí•˜ì—¬ ì›í•˜ëŠ” ì„¼ì„œ ê°™ì´ ê·¸ë¦´ ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457dd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_lowest_bottom_actuals_with_reference_custom_single(\n",
    "    actuals, lotids, wafer_numbers, feature_names,\n",
    "    highest_lowest_df, reference_df,\n",
    "    mask=None,\n",
    "    output_dir=\"custom_overlay_plots_single\",\n",
    "    ref_max_count=100\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "\n",
    "    D = actuals.shape[2]\n",
    "    highest_lowest_df = highest_lowest_df.copy()\n",
    "\n",
    "    sensor_groups = {\n",
    "        'APC_Position': ['APC_Position', 'APC_Pressure', 'Mat_Irms', 'Mat_VC1_Position'],\n",
    "        'APC_Pressure': ['APC_Pressure'],\n",
    "        'Gas1_Monitor': ['Gas1_Monitor', 'Wall_Temp_Monitor'],\n",
    "        'Gas6_Monitor': ['Gas6_Monitor', 'Mat_Irms', 'Mat_VC2_Position'],\n",
    "        'Mat_Irms': ['Mat_Irms', 'APC_Pressure', 'Mat_Vrms', 'Wall_Temp_Monitor'],\n",
    "        'Mat_Phase': ['Mat_Phase', 'Mat_VC2_Position'],\n",
    "        'Wall_Temp_Monitor': ['Wall_Temp_Monitor'],\n",
    "        'Temp': ['Temp','Wall_Temp_Monitor', 'Mat_Irms'],\n",
    "        'SourcePwr_Read': ['APC_Pressure', 'SourcePwr_Read',  'Temp'],\n",
    "        'Mat_Vrms': ['APC_Pressure', 'Mat_Vrms',  'Mat_VC1_Position', 'Temp' ],\n",
    "        'Mat_VC2_Position': ['Mat_VC2_Position', 'Mat_Vrms','Wall_Temp_Monitor'],\n",
    "        'Mat_VC1_Position': ['Mat_VC1_Position', 'APC_Pressure', 'Mat_Phase', 'Mat_VC2_Position', 'Temp', 'Wall_Temp_Monitor'],\n",
    "    }\n",
    "\n",
    "    for key_sensor, related_sensors in sensor_groups.items():\n",
    "        fig, axes = plt.subplots(len(related_sensors), 1, figsize=(10, 3 * len(related_sensors)), sharex=True)\n",
    "\n",
    "        if len(related_sensors) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, sensor in zip(axes, related_sensors):\n",
    "            if sensor not in feature_names:\n",
    "                continue\n",
    "\n",
    "            sensor_idx = feature_names.index(sensor)\n",
    "\n",
    "            # reference\n",
    "            if reference_df is not None and sensor in reference_df.columns:\n",
    "                ref_grouped = reference_df.groupby(['lotid', 'wafer_number'])\n",
    "                ref_keys = random.sample(list(ref_grouped.groups.keys()), min(ref_max_count, len(ref_grouped)))\n",
    "                for key in ref_keys:\n",
    "                    ref_series = ref_grouped.get_group(key).reset_index(drop=True)[sensor].values\n",
    "                    ax.plot(ref_series, color='#999999', alpha=0.5, linewidth=1.0,\n",
    "                            label='Reference' if key == ref_keys[0] else None)\n",
    "\n",
    "            # Highest (1ê°œë§Œ)\n",
    "            top_ids = highest_lowest_df[\n",
    "                (highest_lowest_df['sensor'] == key_sensor) &\n",
    "                (highest_lowest_df['rank_type'] == 'top')\n",
    "            ]['unique_id'].values[:1]\n",
    "\n",
    "            for uid in top_ids:\n",
    "                idxs = np.where(unique_ids == uid)[0]\n",
    "                if len(idxs) == 0:\n",
    "                    continue\n",
    "                idx = idxs[0]\n",
    "                if mask is not None:\n",
    "                    valid = mask[idx] == 1\n",
    "                    actual_seq = actuals[idx, valid, sensor_idx]\n",
    "                else:\n",
    "                    actual_seq = actuals[idx, :, sensor_idx]\n",
    "\n",
    "                ax.plot(actual_seq, color='blue', alpha=0.6, linewidth=1.2,\n",
    "                        label='Highest')\n",
    "\n",
    "            # Lowest (1ê°œë§Œ)\n",
    "            bottom_ids = highest_lowest_df[\n",
    "                (highest_lowest_df['sensor'] == key_sensor) &\n",
    "                (highest_lowest_df['rank_type'] == 'bottom')\n",
    "            ]['unique_id'].values[:1]\n",
    "\n",
    "            for uid in bottom_ids:\n",
    "                idxs = np.where(unique_ids == uid)[0]\n",
    "                if len(idxs) == 0:\n",
    "                    continue\n",
    "                idx = idxs[0]\n",
    "                if mask is not None:\n",
    "                    valid = mask[idx] == 1\n",
    "                    actual_seq = actuals[idx, valid, sensor_idx]\n",
    "                else:\n",
    "                    actual_seq = actuals[idx, :, sensor_idx]\n",
    "\n",
    "                ax.plot(actual_seq, color='red', alpha=0.6, linewidth=1.2,\n",
    "                        label='Lowest')\n",
    "\n",
    "            ax.set_ylabel(sensor)\n",
    "            ax.legend(fontsize=7)\n",
    "            ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        axes[-1].set_xlabel('Time')\n",
    "        fig.suptitle(f\"{key_sensor} | Highest vs Lowest\", fontsize=13)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        save_path = os.path.join(output_dir, f'{key_sensor}_context_overlay_single.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    return f\"âœ… ì €ì¥ ì™„ë£Œ: {output_dir}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2297bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_lowest_bottom_actuals_with_reference_custom_single(\n",
    "    actuals=actuals,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    feature_names=feature_names,\n",
    "    highest_lowest_df=highest_lowest_df,\n",
    "    reference_df=train_scaled,\n",
    "    mask=masks,\n",
    "    output_dir=\"./logs/vtt_all_step/VTTSAT/version5/plots/highest_lowest_context_overlay_single\",\n",
    "    ref_max_count=1163\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af7b25",
   "metadata": {},
   "source": [
    "# Attention difference map ê·¸ë¦¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_by_uid(preds, actuals, lotids, wafer_numbers, masks, target_uid):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ UIDì— í•´ë‹¹í•˜ëŠ” windowë“¤ì„ ë°˜í™˜ (ì…ë ¥ ë°ì´í„°ì™€ mask ëª¨ë‘)\n",
    "    \n",
    "    Args:\n",
    "        preds, actuals: (N, T, D)\n",
    "        masks: (N, T)\n",
    "        lotids, wafer_numbers: ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë°°ì—´\n",
    "        target_uid: 'lotid-wafer_number' í˜•ì‹ì˜ ë¬¸ìì—´\n",
    "\n",
    "    Returns:\n",
    "        input_windows: torch.Tensor of shape (B, T, D)\n",
    "        input_masks: torch.Tensor of shape (B, T)\n",
    "    \"\"\"\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "    indices = np.where(unique_ids == target_uid)[0]\n",
    "    if len(indices) == 0:\n",
    "        raise ValueError(f\"UID '{target_uid}'ì— í•´ë‹¹í•˜ëŠ” window ì—†ìŒ\")\n",
    "\n",
    "    input_windows = actuals[indices]  # ì˜ˆì¸¡ ëŒ€ìƒì€ actual (input)\n",
    "    input_masks = masks[indices]\n",
    "\n",
    "    return torch.tensor(input_windows).float(), torch.tensor(input_masks).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff_attns(prior, post, mask=None):\n",
    "    \"\"\"\n",
    "    prior, post: shape (L, T, H, D, D)\n",
    "    mask: shape (T,) or (1, T), where 1 indicates valid time step\n",
    "\n",
    "    Returns:\n",
    "        diff: shape (D, D) â€“ í‰ê·  diff (ë§ˆìŠ¤í‚¹ ì ìš©ë¨)\n",
    "    \"\"\"\n",
    "    diff = np.abs(post - prior)  # (L, T, H, D, D)\n",
    "\n",
    "    if mask is not None:\n",
    "        if mask.ndim == 2:\n",
    "            mask = mask[0]  # shape: (T,)\n",
    "\n",
    "        # broadcast mask to (L, T, H, D, D)\n",
    "        mask_broadcast = mask[None, :, None, None, None]  # (1, T, 1, 1, 1)\n",
    "        diff = np.where(mask_broadcast, diff, np.nan)     # ë§ˆìŠ¤í‚¹ëœ ë¶€ë¶„ì€ NaN\n",
    "\n",
    "        diff = np.nanmean(diff, axis=(0, 1, 2))            # NaN ì œì™¸ í‰ê· \n",
    "    else:\n",
    "        diff = np.mean(diff, axis=(0, 1, 2))               # ì „ì²´ í‰ê· \n",
    "    return diff  # shape: (D, D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12159bb6",
   "metadata": {},
   "source": [
    "### ê° ì„¼ì„œ ë³„ vtt score ê°€ì¥ ë†’ì€ ì›¨ì´í¼, ê°€ì¥ ë‚®ì€ ì›¨ì´í¼ë“¤ì˜ Attention difference map ë¹„êµë¥¼ ìœ„í•œ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e571ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_diff_top_bottom_per_sensor(\n",
    "    preds, actuals, lotids, wafer_numbers, masks,\n",
    "    highest_lowest_df, model, feature_names,\n",
    "    get_input_by_uid, calc_diff_attns,\n",
    "    save_root='attn_diff_top_bottom', device='cuda'\n",
    "):\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    model.model.eval()\n",
    "\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "\n",
    "    for sensor in highest_lowest_df['sensor'].unique():\n",
    "        if sensor not in feature_names:\n",
    "            continue\n",
    "\n",
    "        sensor_df = highest_lowest_df[highest_lowest_df['sensor'] == sensor]\n",
    "        top_uid = sensor_df[sensor_df['rank_type'] == 'top']['unique_id'].values[0]\n",
    "        bottom_uid = sensor_df[sensor_df['rank_type'] == 'bottom']['unique_id'].values[0]\n",
    "        sensor_idx = feature_names.index(sensor)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        uids = {'Lowest': bottom_uid, 'Highest': top_uid}\n",
    "        diffs = {}\n",
    "\n",
    "        # 1. ë¨¼ì € ë‘ diff ê³„ì‚°\n",
    "        for title, uid in uids.items():\n",
    "            try:\n",
    "                input_seq, input_mask = get_input_by_uid(\n",
    "                    preds, actuals, lotids, wafer_numbers, masks, uid\n",
    "                )\n",
    "                input_seq = input_seq.to(device)\n",
    "                mask_tensor = input_mask.cpu().numpy()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    prior_pred, [prior_vattn, _] = model.model(input_seq, use_attn=True)\n",
    "                    post_pred, [post_vattn, _] = model.model(prior_pred, use_attn=True)\n",
    "\n",
    "                prior_vattn = prior_vattn.cpu().detach().numpy()\n",
    "                post_vattn = post_vattn.cpu().detach().numpy()\n",
    "                diff = calc_diff_attns(prior_vattn, post_vattn, mask_tensor)\n",
    "                diffs[title] = diff\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ì—ëŸ¬] {sensor} | {title} | {uid} ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "                diffs[title] = None\n",
    "\n",
    "        # 2. min, max ê³„ì‚°\n",
    "        valid_diffs = [d for d in diffs.values() if d is not None]\n",
    "        if not valid_diffs:\n",
    "            continue\n",
    "\n",
    "        global_min = min(d.min() for d in valid_diffs)\n",
    "        global_max = max(d.max() for d in valid_diffs)\n",
    "\n",
    "        # 3. colormap ì„¤ì •\n",
    "        h = 24\n",
    "        colors = [\n",
    "            mcl.hsv_to_rgb((h / 360, 0, 1)),\n",
    "            mcl.hsv_to_rgb((h / 360, 0.5, 1)),\n",
    "            mcl.hsv_to_rgb((h / 360, 1, 1))\n",
    "        ]\n",
    "        cmap = LinearSegmentedColormap.from_list('custom_cmap', colors, gamma=3)\n",
    "\n",
    "        # 4. íˆíŠ¸ë§µ ì‹œê°í™”\n",
    "        for i, (title, diff) in enumerate(diffs.items()):\n",
    "            if diff is None:\n",
    "                continue\n",
    "\n",
    "            hm  = sns.heatmap(\n",
    "                diff,\n",
    "                cmap=cmap,\n",
    "                annot=True,\n",
    "                fmt=\".4f\",\n",
    "                annot_kws={\"size\": 4},\n",
    "                xticklabels=feature_names,\n",
    "                yticklabels=feature_names,\n",
    "                cbar=True,\n",
    "                ax=axes[i],\n",
    "                vmin=global_min,\n",
    "                vmax=global_max  # âœ… ê³ ì • ë²”ìœ„!\n",
    "            )\n",
    "\n",
    "            axes[i].set_title(f\"{title}\", fontsize=9)\n",
    "            axes[i].tick_params(axis='x', labelrotation=90, labelsize=6)\n",
    "            axes[i].tick_params(axis='y', labelsize=6)\n",
    "            colorbar = hm.collections[0].colorbar\n",
    "            colorbar.ax.tick_params(labelsize=5)  # â† ìˆ«ì í¬ê¸° 8ptë¡œ ì„¤ì •\n",
    "\n",
    "        plt.suptitle(f\"{sensor} | Attention Difference (Lowest vs Highest)\", fontsize=11)\n",
    "        plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "        save_path = os.path.join(save_root, f\"{sensor}_attn_diff_top_bottom.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    return f\"âœ… ì €ì¥ ì™„ë£Œ: {save_root}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_diff_top_bottom_per_sensor(\n",
    "    preds=preds,\n",
    "    actuals=actuals,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    masks=masks,\n",
    "    highest_lowest_df=highest_lowest_df,\n",
    "    model=model,\n",
    "    feature_names=feature_names,\n",
    "    get_input_by_uid=get_input_by_uid,\n",
    "    calc_diff_attns=calc_diff_attns,\n",
    "    save_root='./logs/vtt_all_step/VTTSAT/version5/plots/attn_diff_highest_lowest',\n",
    "    device='cuda'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "VTT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "ko",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ko",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "344px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
