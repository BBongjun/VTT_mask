{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ff69a0",
   "metadata": {},
   "source": [
    "### SETP 0. 환경 구축하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff07a84",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4300b8",
   "metadata": {},
   "source": [
    "- VTT 모델에 맞는 환경을 구축하기 위하여 필요한 패키지를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22faf9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T06:01:50.100980Z",
     "start_time": "2024-06-09T06:01:50.093114Z"
    }
   },
   "outputs": [],
   "source": [
    "# github에서 데이터 불러오기\n",
    "# !git clone https://github.com/hwk0702/KBS2024-VTT.git\n",
    "# %cd ./KBS2024-VTT/src\n",
    "%cd ../src\n",
    "\n",
    "# !pip install -r ../requirements.txt|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83505a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T06:01:52.415481Z",
     "start_time": "2024-06-09T06:01:50.840036Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # 운영 체제와의 상호작용을 위한 모듈\n",
    "import sys  # 시스템 특정 파라미터와 함수를 위한 모듈\n",
    "import random  # 난수 생성기를 위한 모듈\n",
    "import math  # 수학적 함수와 상수를 위한 모듈\n",
    "import time  # 시간 관련 함수를 위한 모듈\n",
    "import json  # JSON 데이터 파싱과 생성을 위한 모듈\n",
    "import yaml  # YAML 파일 파싱과 생성을 위한 모듈\n",
    "import warnings  # 경고 메시지를 관리하기 위한 모듈\n",
    "warnings.filterwarnings(\"ignore\")  # 경고 메시지를 무시하도록 설정\n",
    "\n",
    "import argparse  # 명령행 옵션, 인자 파싱 모듈\n",
    "from datetime import datetime  # 날짜와 시간 관련 모듈\n",
    "\n",
    "import numpy as np # 다차원 배열과 연산을 다루는 모듈\n",
    "import pandas as pd  # 데이터 조작 및 분석을 위한 라이브러리\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler  # 데이터 전처리를 위한 스케일링 모듈\n",
    "\n",
    "import matplotlib.pyplot as plt  # 데이터 시각화를 위한 라이브러리\n",
    "# %matplotlib inline  # 주피터 노트북에서 인라인으로 그래프를 표시\n",
    "\n",
    "from easydict import EasyDict  # 딕셔너리의 속성을 점 표기법으로 접근할 수 있도록 하는 모듈\n",
    "from omegaconf import OmegaConf  # 설정 파일 관리를 위한 모듈\n",
    "\n",
    "import torch  # 딥러닝을 위한 라이브러리\n",
    "from torch import optim, einsum  # 최적화 및 다차원 배열 연산을 위한 모듈\n",
    "import torch.nn as nn  # 신경망 구축을 위한 모듈\n",
    "from torch.utils.data import Dataset  # 데이터셋 구성을 위한 모듈\n",
    "from torch.nn.utils import weight_norm  # 신경망 가중치 정규화를 위한 모듈\n",
    "\n",
    "from einops import rearrange, repeat  # 배열 재구성 및 반복을 위한 모듈\n",
    "\n",
    "from layers.Transformer_Enc import PreNorm, FeedForward  # 사용자 정의 트랜스포머 인코더 모듈\n",
    "\n",
    "from utils.utils import set_seed, log_setting, version_build  # 유틸리티 함수들\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, check_graph  # 학습 조기 종료 및 학습률 조정 도구\n",
    "from data_provider.waferdataset import get_dataloader  # 데이터 로더 함수\n",
    "from model import build_model  # 모델 빌드 함수\n",
    "\n",
    "# torch 버전 및 디바이스를 확인\n",
    "print(\"Python version:[%s].\" % (sys.version))\n",
    "print(\"PyTorch version:[%s].\" % (torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:[%s].\" % (device))  # GPU를 사용 가능한 경우 'cuda:0'가 출력되면 GPU를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15eff85",
   "metadata": {},
   "source": [
    "모델에 필요한 argument들을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc84ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T06:01:53.052003Z",
     "start_time": "2024-06-09T06:01:53.043970Z"
    }
   },
   "outputs": [],
   "source": [
    "# 설정 인자들을 정의\n",
    "args = EasyDict({\n",
    "    # for dataloader \n",
    "    'dataname': 'vtt_step45_big_ref',\n",
    "    'subdataname': None,\n",
    "    'window_size': 30,\n",
    "    'slide_size': 1,\n",
    "\n",
    "    # for training\n",
    "    'train': True,\n",
    "    'test': True,\n",
    "    'resume': None,\n",
    "    'model': 'VTTSAT',\n",
    "    'epochs': 20,\n",
    "    'patience': 5,\n",
    "\n",
    "    # for loss\n",
    "    'loss': 'mse',\n",
    "\n",
    "    # for setting\n",
    "    'seed': 72,\n",
    "    'use_gpu':True,\n",
    "    'gpu': 0,\n",
    "    'use_multi_gpu': False,\n",
    "    'devices': '0',\n",
    "    'configure': './config.yaml',\n",
    "    'batch_size': 16\n",
    "})\n",
    "\n",
    "# 구성 파일을 로드합니다.\n",
    "with open(args.configure) as f:\n",
    "    config = OmegaConf.load(f)\n",
    "\n",
    "# 로드된 구성 내용을 출력합니다.\n",
    "print(OmegaConf.to_yaml(config, resolve=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b5a55",
   "metadata": {},
   "source": [
    "### STEP 9. XAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a28592",
   "metadata": {},
   "source": [
    "<img src=\"../image/XAI.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b64cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T07:22:40.816468Z",
     "start_time": "2024-06-09T07:22:40.772627Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcl\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f60e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def load_inference_result(h5_path):\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        preds = f['pred'][:]\n",
    "        actuals = f['actual'][:]\n",
    "        lotids = f['lotid'][:].astype(str)\n",
    "        wafer_numbers = f['wafer_number'][:].astype(str)\n",
    "        step_nums = f['step_num'][:]\n",
    "        masks = f['mask'][:]\n",
    "        dist_per_feature = f['dist_per_window_per_features'][:] if 'dist_per_window_per_features' in f else None\n",
    "\n",
    "    return preds, actuals, dist_per_feature, lotids, wafer_numbers, step_nums, masks\n",
    "\n",
    "# main.py --test 로 실행 후, 추출되는 파일 필요 (inference_result_with_metadata.h5)\n",
    "h5_path = './logs/vtt_all_step/VTTSAT/version5/results/inference_result_with_metadata.h5'\n",
    "preds, actuals, dist_per_feature, lotids, wafer_numbers, step_nums, masks = load_inference_result(h5_path)\n",
    "\n",
    "masks = masks.reshape(16808, 350)\n",
    "\n",
    "feature_names = [\n",
    "    'APC_Position',\n",
    "    'APC_Pressure',\n",
    "    'Gas1_Monitor',\n",
    "    'Gas6_Monitor',\n",
    "    'Mat_Irms',\n",
    "    'Mat_Vrms',\n",
    "    'Mat_VC1_Position',\n",
    "    'Mat_VC2_Position',\n",
    "    'SourcePwr_Read',\n",
    "    'Temp',\n",
    "    'Wall_Temp_Monitor'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "def visualize_overlay_all_wafers_subplots(\n",
    "    preds, actuals, lotids, wafer_numbers, feature_names, masks,\n",
    "    output_path='overlay_all_wafers_subplots.png', num_wafer_to_plot=1000, seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    12개 센서를 (3,4) subplot으로 시각화. 각 subplot에는 여러 웨이퍼가 겹쳐져 있음.\n",
    "    (웨이퍼 하나당 시계열 전체를 하나의 샘플로 사용하는 경우에 맞게 수정됨)\n",
    "    \"\"\"\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "    unique_wafer_ids = np.unique(unique_ids)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    selected_indices = np.random.choice(len(unique_ids), size=min(num_wafer_to_plot, len(unique_ids)), replace=False)\n",
    "\n",
    "    T = preds.shape[1]\n",
    "    D = preds.shape[2]\n",
    "\n",
    "    # 시각화\n",
    "    n_rows, n_cols = 3, 4\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows), sharex=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for d in range(D):\n",
    "        ax = axes[d]\n",
    "\n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            actual_seq = actuals[idx, :, d]\n",
    "            pred_seq = preds[idx, :, d]\n",
    "            \n",
    "            mask_seq = masks[idx]\n",
    "            time_indices = np.where(mask_seq ==1)[0]\n",
    "            actual_seq = actual_seq[time_indices]\n",
    "            pred_seq = pred_seq[time_indices]\n",
    "\n",
    "            label_actual = 'Actual' if i == 0 else None\n",
    "            label_pred = 'Predicted' if i == 0 else None\n",
    "\n",
    "            ax.plot(actual_seq, color='blue', alpha=0.2, linewidth=0.8, label=label_actual, zorder=0)\n",
    "            ax.plot(pred_seq, color='magenta', alpha=0.2, linewidth=0.8, label=label_pred, zorder=1)\n",
    "\n",
    "        ax.set_title(feature_names[d], fontsize=10, fontweight='bold')\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        # ax.grid(True, linestyle='-', linewidth=1.0, color='gray', alpha=0.4)\n",
    "\n",
    "        if d == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "\n",
    "    for j in range(D, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    fig.suptitle(f'Overlay of {len(selected_indices)} Wafers per Sensor', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"✅ 저장 완료: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0878e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_overlay_all_wafers_subplots(\n",
    "    preds=preds,\n",
    "    actuals=actuals,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    feature_names=feature_names,\n",
    "    masks=masks,\n",
    "    output_path='./logs/vtt_all_step/VTTSAT/version5/plots/overlay_all_wafers_subplots.png',\n",
    "    num_wafer_to_plot=16808\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265dda5",
   "metadata": {},
   "source": [
    "## step 별로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def compute_vtt_score_per_stepnum(preds, actuals, masks, lotids, wafer_numbers, step_nums, feature_names):\n",
    "    \"\"\"\n",
    "    step_num별로 VTT score(MAE, masking 적용)를 계산하고 하나의 DataFrame으로 정리 (전체 시계열 1개 per wafer)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: columns = [step, unique_id, sensor1, ..., sensorN]\n",
    "    \"\"\"\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "    step_nums = np.array(step_nums)\n",
    "\n",
    "    D = preds.shape[2]\n",
    "    result_records = []\n",
    "\n",
    "    for step in sorted(np.unique(step_nums)):\n",
    "        # 🔹 해당 step만 추출\n",
    "        step_mask = step_nums == step\n",
    "        step_preds = preds[step_mask]\n",
    "        step_actuals = actuals[step_mask]\n",
    "        step_masks = masks[step_mask]\n",
    "        step_ids = unique_ids[step_mask]\n",
    "\n",
    "        for i, uid in enumerate(step_ids):\n",
    "            pred = step_preds[i]        # (T, D)\n",
    "            actual = step_actuals[i]    # (T, D)\n",
    "            mask = step_masks[i]        # (T,)\n",
    "\n",
    "            valid_idx = mask == 1\n",
    "            if not np.any(valid_idx):\n",
    "                continue\n",
    "\n",
    "            mae_per_feature = -np.sum(np.abs(pred[valid_idx] - actual[valid_idx]), axis=0)  # (D,)\n",
    "            record = {'step': int(step), 'unique_id': uid}\n",
    "            record.update({feature_names[d]: mae_per_feature[d] for d in range(D)})\n",
    "            result_records.append(record)\n",
    "\n",
    "    return pd.DataFrame.from_records(result_records)\n",
    "\n",
    "\n",
    "vtt_stepwise_scores_df = compute_vtt_score_per_stepnum(\n",
    "    preds=preds,\n",
    "    actuals=actuals,\n",
    "    masks=masks,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    step_nums=step_nums,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "\n",
    "vtt_stepwise_scores_df.to_csv('./logs/vtt_all_step/VTTSAT/version5/plots/vtt_scores_per_wafer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3364c",
   "metadata": {},
   "source": [
    "## step 구분없이 스코어 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vtt_score_all_wafer(preds, actuals, masks, lotids, wafer_numbers, feature_names):\n",
    "    \"\"\"\n",
    "    VTT score(MAE, masking 적용)를 웨이퍼 단위로 계산\n",
    "    step_num 구분 없이 전체에 대해 계산\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: columns = [unique_id, sensor1, ..., sensorN]\n",
    "    \"\"\"\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "\n",
    "    D = preds.shape[2]\n",
    "    result_records = []\n",
    "\n",
    "    for i, uid in enumerate(unique_ids):\n",
    "        pred = preds[i]        # (T, D)\n",
    "        actual = actuals[i]    # (T, D)\n",
    "        mask = masks[i]        # (T,)\n",
    "\n",
    "        valid_idx = mask == 1\n",
    "        if not np.any(valid_idx):\n",
    "            continue\n",
    "\n",
    "        mae_per_feature = -np.sum(np.abs(pred[valid_idx] - actual[valid_idx]), axis=0)  # (D,)\n",
    "        record = {'unique_id': uid}\n",
    "        record.update({feature_names[d]: mae_per_feature[d] for d in range(D)})\n",
    "        result_records.append(record)\n",
    "\n",
    "    return pd.DataFrame.from_records(result_records)\n",
    "\n",
    "\n",
    "vtt_all_scores_df = compute_vtt_score_all_wafer(\n",
    "    preds=preds,\n",
    "    actuals=actuals,\n",
    "    masks=masks,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    feature_names=feature_names\n",
    ")\n",
    "vtt_all_scores_df.to_csv('./logs/vtt_all_step/VTTSAT/version5/results/vtt_scores_per_wafer_allstep.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91508003",
   "metadata": {},
   "source": [
    "# XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정 인자들을 정의\n",
    "args = EasyDict({\n",
    "    # for dataloader \n",
    "    'dataname': 'vtt_all_step',\n",
    "    'subdataname': None,\n",
    "    'window_size': 30,\n",
    "    'slide_size': 1,\n",
    "\n",
    "    # for training\n",
    "    'train': True,\n",
    "    'test': True,\n",
    "    'resume': 5,\n",
    "    'model': 'VTTSAT',\n",
    "    'epochs': 20,\n",
    "    'patience': 5,\n",
    "\n",
    "    # for loss\n",
    "    'loss': 'mse',\n",
    "\n",
    "    # for setting\n",
    "    'seed': 72,\n",
    "    'use_gpu':True,\n",
    "    'gpu': 0,\n",
    "    'use_multi_gpu': False,\n",
    "    'devices': '0',\n",
    "    'configure': './config.yaml',\n",
    "    'batch_size': 16\n",
    "})\n",
    "\n",
    "# 구성 파일을 로드합니다.\n",
    "with open(args.configure) as f:\n",
    "    config = OmegaConf.load(f)\n",
    "\n",
    "# 로드된 구성 내용을 출력합니다.\n",
    "print(OmegaConf.to_yaml(config, resolve=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f76dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 디렉토리와 저장 디렉토리를 설정\n",
    "logdir = os.path.join(config.log_dir, f'{args.dataname}/{args.model}')\n",
    "savedir = version_build(logdir=logdir, is_train=args.train, resume=args.resume)\n",
    "\n",
    "# GPU 사용 설정을 구성\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    # GPU 디바이스 목록을 설정\n",
    "    args.devices = args.devices.replace(' ', '')\n",
    "    args.device_ids = list(map(int, args.devices.split(',')))\n",
    "    args.gpu = args.device_ids[0]  # 첫 번째 GPU를 기본 GPU로 설정\n",
    "\n",
    "# 랜덤 시드를 설정\n",
    "set_seed(args.seed)\n",
    "\n",
    "# 모델 파라미터를 설정\n",
    "model_params = config[args.model]\n",
    "\n",
    "# # 모델 파라미터를 수정(실험 세팅 가볍게)\n",
    "# model_params.n_layer = 1\n",
    "# model_params.n_head = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a862e73",
   "metadata": {},
   "source": [
    "### SETP 1. 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "\"\"\"\n",
    "GDN에 적합하도록 WaferDataset을 변환한 데이터셋 클래스\n",
    "dataset_preprocessing.ipynb에서 생성하여, h5 파일 이용\n",
    "\"\"\"\n",
    "class WaferDataset(Dataset):\n",
    "    def __init__(self, file_list, model_type='reconstruction', max_len = 350):\n",
    "        self.file_list = file_list\n",
    "        self.model_type = model_type\n",
    "        self.max_seq_len = max_len\n",
    "\n",
    "        self.data, self.labels = [], []\n",
    "        self.masks = []\n",
    "        self.lengths = []\n",
    "        self.lotids = []\n",
    "        self.wafer_numbers = []\n",
    "        self.step_nums = []\n",
    "\n",
    "        for file_path in tqdm(file_list, desc=\"Loading and merging data\"):\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                raw_data = f['data'][:].astype(float)\n",
    "                T_i = raw_data.shape[0]\n",
    "                C = raw_data.shape[1]\n",
    "                # D = raw_data.shape[2]\n",
    "                # print(T_i, C)\n",
    "                # padding\n",
    "                if T_i < self.max_seq_len:\n",
    "                    padded = np.zeros((self.max_seq_len, C))\n",
    "                    padded[:T_i] = raw_data # 뒷 부분은 zero padding\n",
    "                    mask = np.zeros((self.max_seq_len,), dtype=np.float32)\n",
    "                    mask[:T_i] = 1.0\n",
    "                else : \n",
    "                    padded = raw_data[:self.max_seq_len]\n",
    "                    mask = np.ones((self.max_seq_len,), dtype=np.float32)\n",
    "                    \n",
    "                self.data.append(torch.tensor(padded, dtype=torch.float32))\n",
    "                self.masks.append(torch.tensor(mask, dtype=torch.float32))\n",
    "                \n",
    "                # self.labels.append(f['labels'][:])\n",
    "                self.lengths.append(min(T_i, self.max_seq_len))\n",
    "                \n",
    "                self.lotids.extend(f['lotids'][:].astype(str))\n",
    "                self.wafer_numbers.extend(f['wafer_numbers'][:].astype(str))\n",
    "                self.step_nums.extend(f['step_num'][:])\n",
    "\n",
    "        # self.all_data = np.concatenate(all_data, axis=0)\n",
    "        # self.all_next_steps = np.concatenate(all_next_steps, axis=0)\n",
    "        # self.all_labels = np.concatenate(all_labels, axis=0)\n",
    "        # self.n_sensor = self.data.shape[2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'given': self.data[idx],           # (max_seq_len, C)\n",
    "            'mask': self.masks[idx],           # (max_seq_len,)\n",
    "            'length': self.lengths[idx],       # int\n",
    "            # 'label': self.labels[idx],         # int\n",
    "            'lotid': self.lotids[idx],\n",
    "            'wafer_number': self.wafer_numbers[idx],\n",
    "            'step_num': self.step_nums[idx],\n",
    "        }\n",
    "\n",
    "        if self.model_type == 'reconstruction':\n",
    "            item['answer'] = self.data[idx]\n",
    "        # elif self.model_type == 'prediction':\n",
    "        #     item['answer'] = self.data[idx][1:]  # 예: 다음 스텝 예측 등\n",
    "        return item\n",
    "\n",
    "def get_dataloader(data_info, loader_params: dict):\n",
    "    \"\"\"\n",
    "    GDN 모델에 적합한 DataLoader 생성 함수 (train/val split 포함)\n",
    "\n",
    "    Args:\n",
    "        data_info (dict): 'train_dir' 키 포함\n",
    "        loader_params (dict): batch_size, use_val 등 포함\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader or None, test_loader)\n",
    "    \"\"\"\n",
    "    # 전체 train 파일 리스트\n",
    "    train_files = sorted([\n",
    "        os.path.join(data_info['train_dir'], f)\n",
    "        for f in os.listdir(data_info['train_dir'])\n",
    "        if f.endswith(\".h5\")\n",
    "    ])\n",
    "\n",
    "    # validation 포함 여부\n",
    "    if loader_params['use_val']:\n",
    "        val_files = sorted([\n",
    "        os.path.join(data_info['val_dir'], f)\n",
    "        for f in os.listdir(data_info['val_dir'])\n",
    "        if f.endswith(\".h5\")\n",
    "    ])\n",
    "\n",
    "        val_dataset = WaferDataset(val_files)\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=loader_params['batch_size'],\n",
    "                                shuffle=False,\n",
    "                                num_workers=0,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=False)\n",
    "    else:\n",
    "        val_loader = None\n",
    "\n",
    "    # test 파일 리스트 (필요시 별도 dir로 교체 가능)\n",
    "    test_files = sorted([\n",
    "        os.path.join(data_info['test_dir'], f)\n",
    "        for f in os.listdir(data_info['test_dir'])\n",
    "        if f.endswith(\".h5\")\n",
    "    ])\n",
    "\n",
    "    # Dataset & DataLoader\n",
    "    train_dataset = WaferDataset(train_files)\n",
    "    test_dataset = WaferDataset(test_files)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=loader_params['batch_size'],\n",
    "                              shuffle=True,\n",
    "                              num_workers=0,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=loader_params['batch_size'],\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=True,\n",
    "                             drop_last=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = config[args.dataname]\n",
    "\n",
    "trainloader, validloader, testloader = get_dataloader(data_info = data_info,\n",
    "                                                        loader_params = config['loader_params'])        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac25c1f",
   "metadata": {},
   "source": [
    "# 모델 code 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "    \n",
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, groups=1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out[:, :, : -self.conv.padding[0]]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import einsum\n",
    "from einops import rearrange, repeat\n",
    "import math\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "\n",
    "class VariableAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim,\n",
    "            heads=8,\n",
    "            dim_head=16,\n",
    "            dropout=0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, use_attn):\n",
    "        b, t, f, d = x.shape\n",
    "        x = rearrange(x, 'b t f d -> (b t) f d')\n",
    "        h = self.heads\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda m: rearrange(m, 'b n (h d) -> b h n d', h=h), (q, k, v))\n",
    "        sim = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = sim.softmax(dim=-1)\n",
    "        if use_attn:\n",
    "            weights = attn\n",
    "        else:\n",
    "            weights = None\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)', h=h)\n",
    "        out = self.to_out(out)\n",
    "        out = rearrange(out, '(b t) f d -> b t f d', t=t)\n",
    "        return out, weights\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dim_head=16, dropout=0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, use_attn=False, mask=None):\n",
    "        b, t, f, d = x.shape\n",
    "        x = rearrange(x, 'b t f d -> (b f) t d')  # across time\n",
    "        h = self.heads\n",
    "\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda m: rearrange(m, 'b n (h d) -> b h n d', h=h), (q, k, v))\n",
    "\n",
    "        sim = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale  # (b*f, h, t, t)\n",
    "\n",
    "        if mask is not None:\n",
    "            # mask: (B, T) → (b*f, 1, 1, T)\n",
    "            mask = repeat(mask, 'b t -> (b f) t', f=f)\n",
    "            mask = rearrange(mask, 'b j -> b 1 1 j')\n",
    "            sim = sim.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn = sim.softmax(dim=-1)\n",
    "        weights = attn if use_attn else None\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)', h=h)\n",
    "        out = self.to_out(out)\n",
    "        out = rearrange(out, '(b f) t d -> b t f d', f=f)\n",
    "        return out, weights\n",
    "\n",
    "class VariableTemporalAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim,\n",
    "            heads=8,\n",
    "            dim_head=16,\n",
    "            dropout=0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.variable_to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.variable_to_out = nn.Linear(inner_dim, dim)\n",
    "        self.variable_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.temporal_to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "        self.temporal_to_out = nn.Linear(inner_dim, dim)\n",
    "        self.temporal_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.linear = nn.Linear(dim * 2, dim)\n",
    "\n",
    "    def forward(self, x, use_attn):\n",
    "        b, t, f, d = x.shape\n",
    "\n",
    "        vx = rearrange(x, 'b t f d -> (b t) f d')\n",
    "        h = self.heads\n",
    "        vq, vk, vv = self.variable_to_qkv(vx).chunk(3, dim=-1)\n",
    "        vq, vk, vv = map(lambda m: rearrange(m, 'b n (h d) -> b h n d', h=h), (vq, vk, vv))\n",
    "        sim = einsum('b h i d, b h j d -> b h i j', vq, vk) * self.scale\n",
    "\n",
    "        vattn = sim.softmax(dim=-1)\n",
    "        if use_attn:\n",
    "            vweights = vattn\n",
    "        else:\n",
    "            vweights = None\n",
    "        vattn = self.variable_dropout(vattn)\n",
    "\n",
    "        vout = einsum('b h i j, b h j d -> b h i d', vattn, vv)\n",
    "        vout = rearrange(vout, 'b h n d -> b n (h d)', h=h)\n",
    "        vout = self.variable_to_out(vout)\n",
    "        vout = rearrange(vout, '(b t) f d -> b t f d', t=t)\n",
    "\n",
    "        tx = rearrange(x, 'b t f d -> (b f) t d')\n",
    "        tq, tk, tv = self.temporal_to_qkv(tx).chunk(3, dim=-1)\n",
    "        tq, tk, tv = map(lambda m: rearrange(m, 'b n (h d) -> b h n d', h=h), (tq, tk, tv))\n",
    "        sim = einsum('b h i d, b h j d -> b h i j', tq, tk) * self.scale\n",
    "\n",
    "        tattn = sim.softmax(dim=-1)\n",
    "        if use_attn:\n",
    "            tweights = tattn\n",
    "        else:\n",
    "            tweights = None\n",
    "        tattn = self.temporal_dropout(tattn)\n",
    "\n",
    "        tout = einsum('b h i j, b h j d -> b h i d', tattn, tv)\n",
    "        tout = rearrange(tout, 'b h n d -> b n (h d)', h=h)\n",
    "        tout = self.temporal_to_out(tout)\n",
    "        tout = rearrange(tout, '(b f) t d -> b t f d', f=f)\n",
    "\n",
    "        out = torch.cat([vout, tout], dim=-1)\n",
    "        out = self.linear(out)\n",
    "        return out, vweights, tweights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7a30",
   "metadata": {},
   "source": [
    "#### VTT-SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e292d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VTTSAT(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(VTTSAT, self).__init__()\n",
    "        self.feature_num = params['feature_num']\n",
    "        self.num_transformer_blocks = params['n_layer']\n",
    "        self.num_heads = params['n_head']\n",
    "        self.embedding_dims = params['hidden_size']\n",
    "        self.attn_dropout = params['attn_pdrop']\n",
    "        self.ff_dropout = params['resid_pdrop']\n",
    "        self.time_emb = params['time_emb']\n",
    "\n",
    "        # position 인코딩과 value 인코딩 레이어 정의\n",
    "        self.position_embedding = PositionalEmbedding(d_model=self.embedding_dims)\n",
    "        self.value_embedding = nn.Linear(self.time_emb, self.embedding_dims)\n",
    "\n",
    "        # CausalConv1d 레이어 정의\n",
    "        kernel_sizes = [4, 8, 16]\n",
    "        dilations = [1, 2, 3]\n",
    "        self.causal_convs = nn.ModuleList([\n",
    "            CausalConv1d(self.feature_num, self.feature_num, kernel_size=k, dilation=d, groups=self.feature_num)\n",
    "            for k, d in zip(kernel_sizes, dilations)\n",
    "        ])\n",
    "\n",
    "        # transformer 레이어 정의          \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                PreNorm(self.embedding_dims, VariableAttention(self.embedding_dims, \n",
    "                                                               heads=self.num_heads, \n",
    "                                                               dim_head=self.embedding_dims, \n",
    "                                                               dropout=self.attn_dropout)),\n",
    "                PreNorm(self.embedding_dims, TemporalAttention(self.embedding_dims, \n",
    "                                                               heads=self.num_heads, \n",
    "                                                               dim_head=self.embedding_dims, \n",
    "                                                               dropout=self.attn_dropout)),\n",
    "                PreNorm(self.embedding_dims, FeedForward(self.embedding_dims, dropout=self.ff_dropout))\n",
    "            ]) for _ in range(self.num_transformer_blocks)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(self.ff_dropout)\n",
    "        self.mlp_head = nn.Linear(self.feature_num*self.embedding_dims, self.feature_num)\n",
    "\n",
    "    def forward(self, x, use_attn=False, mask=None):\n",
    "        variable_attn_weights = []\n",
    "        temporal_attn_weights = []\n",
    "        # print(x.shape)\n",
    "        b, w, f = x.shape\n",
    "        x = rearrange(x, 'b w f -> b f w')\n",
    "        conv1 = self.causal_conv1(x)\n",
    "        conv2 = self.causal_conv2(x)\n",
    "        conv3 = self.causal_conv3(x)\n",
    "\n",
    "        x = torch.stack([x, conv1, conv2, conv3], dim=-1)\n",
    "        x = rearrange(x, 'b f w d -> b w f d')\n",
    "        x = self.value_embedding(x)\n",
    "\n",
    "        position_emb = self.position_embedding(x)\n",
    "        position_emb = repeat(position_emb, 'b t d -> b t f d', f=f)\n",
    "        x += position_emb\n",
    "        x = self.dropout(x)\n",
    "        h = x\n",
    "\n",
    "        for vattn, tattn, ff in self.transformer_layers:\n",
    "            x, weights = vattn(h, use_attn=use_attn)\n",
    "            h = x + h\n",
    "            variable_attn_weights.append(weights)\n",
    "            x, weights = tattn(h, use_attn=use_attn, mask = mask)\n",
    "            h = x + h\n",
    "            temporal_attn_weights.append(weights)\n",
    "            x = ff(x)\n",
    "            h = x + h\n",
    "\n",
    "        h = rearrange(h, 'b w f d -> b w (f d)')\n",
    "        h = self.mlp_head(h)\n",
    "        \n",
    "        # Convert lists to tensors\n",
    "        if use_attn:\n",
    "            variable_attn_weights = torch.stack(variable_attn_weights, dim=0)\n",
    "            temporal_attn_weights = torch.stack(temporal_attn_weights, dim=0)\n",
    "\n",
    "        return h, [variable_attn_weights, temporal_attn_weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e3d81",
   "metadata": {},
   "source": [
    "#### VTT-PAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ec358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VTTPAT(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(VTTPAT, self).__init__()\n",
    "        self.feature_num = params['feature_num']\n",
    "        self.num_transformer_blocks = params['n_layer']\n",
    "        self.num_heads = params['n_head']\n",
    "        self.embedding_dims = params['hidden_size']\n",
    "        self.attn_dropout = params['attn_pdrop']\n",
    "        self.ff_dropout = params['resid_pdrop']\n",
    "        self.time_emb = params['time_emb']\n",
    "\n",
    "        # position 인코딩과 value 인코딩 레이어 정의\n",
    "        self.position_embedding = PositionalEmbedding(d_model=self.embedding_dims)\n",
    "        self.value_embedding = nn.Linear(self.time_emb, self.embedding_dims)\n",
    "\n",
    "        # CausalConv1d 레이어 정의\n",
    "        kernel_sizes = [4, 8, 16]\n",
    "        dilations = [1, 2, 3]\n",
    "        self.causal_convs = nn.ModuleList([\n",
    "            CausalConv1d(self.feature_num, self.feature_num, kernel_size=k, dilation=d, groups=self.feature_num)\n",
    "            for k, d in zip(kernel_sizes, dilations)\n",
    "        ])\n",
    "\n",
    "        # transformer 레이어 정의  \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            PreNorm(self.embedding_dims, \n",
    "                    VariableTemporalAttention(self.embedding_dims, \n",
    "                                              heads=self.num_heads, \n",
    "                                              dim_head=self.embedding_dims, \n",
    "                                              dropout=self.attn_dropout))\n",
    "            for _ in range(self.num_transformer_blocks)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(self.ff_dropout)\n",
    "        self.mlp_head = nn.Linear(self.feature_num*self.embedding_dims, self.feature_num)\n",
    "\n",
    "\n",
    "    def forward(self, x, use_attn=False):\n",
    "        variable_attn_weights = []\n",
    "        temporal_attn_weights = []\n",
    "        b, w, f = x.shape\n",
    "\n",
    "        # 입력을 재구성하여 CausalConv1d 적용\n",
    "        x = rearrange(x, 'b w f -> b f w')\n",
    "        conv_outputs = [conv(x) for conv in self.causal_convs]\n",
    "        x = torch.stack([x, conv1, conv2, conv3], dim=-1)\n",
    "        x = rearrange(x, 'b f w d -> b w f d')\n",
    "        x = self.value_embedding(x)\n",
    "\n",
    "        # position 인코딩 추가\n",
    "        position_emb = self.position_embedding(x)\n",
    "        position_emb = repeat(position_emb, 'b t d -> b t f d', f=f)\n",
    "        x += position_emb\n",
    "        x = self.dropout(x)\n",
    "        h = x\n",
    "        \n",
    "        # transformer 레이어 순차적으로 적용\n",
    "        for attn in self.transformer_layers:\n",
    "            x, vweights, tweights = attn(h, use_attn=use_attn)\n",
    "            h = x + h\n",
    "            variable_attn_weights.append(vweights)\n",
    "            temporal_attn_weights.append(tweights)\n",
    "\n",
    "        # 출력 레이어 적용\n",
    "        h = rearrange(h, 'b w f d -> b w (f d)')\n",
    "        h = self.mlp_head(h)\n",
    "        return h, [variable_attn_weights, temporal_attn_weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04901b3",
   "metadata": {},
   "source": [
    "### STEP 6. Build model 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee185b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VTTPAT, VTTSAT\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, check_graph\n",
    "from utils.utils import load_model, CheckPoint\n",
    "from utils.metrics import bf_search\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from einops import rearrange\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import json\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class build_model():\n",
    "    \"\"\"\n",
    "    Build and train or test a model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args : dict\n",
    "        arguments\n",
    "    params : dict\n",
    "        model's hyper parameters\n",
    "    savedir : str\n",
    "        save directory\n",
    "\n",
    "    Attributes\n",
    "    ------------\n",
    "    args : dict\n",
    "        arguments\n",
    "    params : dict\n",
    "        model's hyper parameters\n",
    "    savedir : str\n",
    "        save directory\n",
    "    device : torch.device\n",
    "        device\n",
    "    model : nn.module\n",
    "        model\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _build_model()\n",
    "        Select the model you want to train or test and build it\n",
    "        + multi gpu setting\n",
    "    _acquire_device()\n",
    "        check gpu usage\n",
    "    _select_optimizer()\n",
    "        select the optimizer (default AdamW)\n",
    "    _select_criterion()\n",
    "        select the criterion (default MSELoss)\n",
    "    valid()\n",
    "\n",
    "    train()\n",
    "\n",
    "    test()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args, params, savedir):\n",
    "        super(build_model, self).__init__()\n",
    "        self.args = args\n",
    "        self.params = params\n",
    "        self.savedir = savedir\n",
    "        self.device = self._acquire_device()\n",
    "        self.model = self._build_model().to(self.device)\n",
    "\n",
    "    def _build_model(self):\n",
    "        model_dict = {\n",
    "            'VTTSAT': VTTSAT,\n",
    "            'VTTPAT': VTTPAT,\n",
    "        }\n",
    "        \n",
    "        model = model_dict[self.args.model].Model(self.params).float()\n",
    "        \n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            print('using multi-gpu')\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _acquire_device(self):\n",
    "        if self.args.use_gpu:\n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
    "                self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n",
    "            device = torch.device('cuda:{}'.format(self.args.gpu))\n",
    "            print('Use GPU: cuda:{}'.format(self.args.gpu))\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print('Use CPU')\n",
    "        return device\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        if self.params.optim == 'adamw':\n",
    "            model_optim = optim.AdamW(self.model.parameters(), lr=self.params.lr)\n",
    "        elif self.params.optim == 'adam':\n",
    "            model_optim = optim.Adam(self.model.parameters(), lr=self.params.lr)\n",
    "        elif self.params.optim == 'sgd':\n",
    "            model_optim = optim.SGD(self.model.parameters(), lr=self.params.lr)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        if self.args.loss == 'mse':\n",
    "            criterion = nn.MSELoss(reduction='none')\n",
    "        elif self.args.loss == 'mae':\n",
    "            criterion = nn.L1Loss(reduction='none')\n",
    "        return criterion\n",
    "    \n",
    "    def valid(self, valid_loader, criterion, epoch):\n",
    "        \"\"\"\n",
    "        validation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        valid_loader : torch.utils.data.DataLoader\n",
    "            given : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                input time-series data\n",
    "            ts : ndarray (shape=(batch size, window size))\n",
    "                input timestamp\n",
    "            answer : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                target time-series data\n",
    "                If model_type is prediction, window size is 1\n",
    "\n",
    "        criterion\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        total_loss\n",
    "\n",
    "        \"\"\"\n",
    "        total_loss = []\n",
    "        valid_score = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():               \n",
    "            for batch_idx, batch in enumerate(valid_loader):\n",
    "                batch_x = batch['given'].float().to(self.device)\n",
    "                batch_y = batch['answer'].float().to(self.device)\n",
    "\n",
    "                if self.args.model in ['VTTSAT', 'VTTPAT']:\n",
    "                    output, _ = self.model(batch_x)\n",
    "                    loss = criterion(output, batch_y)\n",
    "                    valid_score.append(np.mean(loss.cpu().detach().numpy(), axis=2))\n",
    "                    loss = torch.mean(loss)\n",
    "                else:\n",
    "                    output = self.model(batch_x)\n",
    "                    loss = criterion(output, batch_y)\n",
    "                    valid_score.append(np.mean(loss.cpu().detach().numpy(), axis=2))\n",
    "                    loss = torch.mean(loss)\n",
    "                \n",
    "                total_loss.append(loss.item())\n",
    "\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss, valid_score\n",
    "\n",
    "    def train(self, train_loader, valid_loader, test_loader, use_val=False,alpha=.5, beta=.5):\n",
    "        \"\"\"\n",
    "        training\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_loader : torch.utils.data.DataLoader\n",
    "            given : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                input time-series data\n",
    "            ts : ndarray (shape=(batch size, window size))\n",
    "                input timestamp\n",
    "            answer : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                target time-series data\n",
    "                If model_type is prediction, window size is 1\n",
    "        valid_loader\n",
    "            given : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                input time-series data\n",
    "            ts : ndarray (shape=(batch size, window size))\n",
    "                input timestamp\n",
    "            answer : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                target time-series data\n",
    "                If model_type is prediction, window size is 1\n",
    "        test_loader\n",
    "            given : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                input time-series data\n",
    "            ts : ndarray (shape=(batch size, window size))\n",
    "                input timestamp\n",
    "            answer : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                target time-series data\n",
    "                If model_type is prediction, window size is 1\n",
    "            attack : ndarray\n",
    "            attack labels\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        model\n",
    "\n",
    "        \"\"\"\n",
    "        time_now = time.time()\n",
    "        best_metrics = None\n",
    "        \n",
    "        if self.args.resume is not None:\n",
    "            print(f'resume version{self.args.resume}')\n",
    "            weights, start_epoch, self.args.lr, best_metrics = load_model(resume=self.args.resume,\n",
    "                                                                          logdir=self.savedir)\n",
    "            if isinstance(self.model, nn.DataParallel):\n",
    "                self.model.module.load_state_dict(weights)\n",
    "            else:\n",
    "                self.model.load_state_dict(weights, map_location=self.device)\n",
    "\n",
    "        # set checkpoint\n",
    "        ckp = CheckPoint(logdir=self.savedir,\n",
    "                         last_metrics=best_metrics,\n",
    "                         metric_type='loss')\n",
    "\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "        \n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "\n",
    "        history = {'train_loss': [], 'validation_loss': []}\n",
    "        \n",
    "        for epoch in range(self.args.epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "            train_score = []\n",
    "\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            \n",
    "            with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{self.args.epochs}\") as pbar:\n",
    "                for batch_idx, batch in enumerate(train_loader):\n",
    "                    iter_count += 1\n",
    "\n",
    "                    batch_x = batch['given'].float().to(self.device)\n",
    "                    batch_y = batch['answer'].float().to(self.device)\n",
    "                    batch_mask = batch['mask'].float().to(self.device)\n",
    "\n",
    "                    model_optim.zero_grad()\n",
    "\n",
    "                    if self.args.model in ['VTTSAT', 'VTTPAT']:\n",
    "                        output, _ = self.model(batch_x, use_attn=False, mask=batch_mask)\n",
    "                    else:\n",
    "                        output = self.model(batch_x)\n",
    "\n",
    "                    # loss 계산 및 마스킹\n",
    "                    loss_raw = criterion(output, batch_y)                   # (B, T, D)\n",
    "                    loss_masked = loss_raw * batch_mask.unsqueeze(-1)      # (B, T, D)\n",
    "                    loss = loss_masked.sum() / batch_mask.sum()            # scalar\n",
    "\n",
    "                    # score 저장 (B, T): D축 평균\n",
    "                    train_score.append(loss_masked.detach().cpu().numpy().mean(axis=2))\n",
    "                    train_loss.append(loss.item())\n",
    "\n",
    "                    # backprop\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "            train_score = np.concatenate(train_score).flatten()\n",
    "            train_loss_avg = np.average(train_loss)\n",
    "            \n",
    "            if use_val:\n",
    "                valid_loss, valid_score = self.valid(valid_loader, criterion, epoch)\n",
    "                valid_score = np.concatenate(valid_score).flatten()\n",
    "            \n",
    "            # 테스트셋(label이 있는) inference\n",
    "            # dist, attack = self.inference(test_loader, epoch)\n",
    "\n",
    "            # result save\n",
    "            # folder_path = os.path.join(self.savedir, 'results', f'epoch_{epoch}')\n",
    "            # os.makedirs(folder_path, exist_ok=True)\n",
    "            # visual = check_graph(dist, attack, piece=4)\n",
    "            # visual.savefig(os.path.join(folder_path, f'graph.png'))\n",
    "            # np.save(os.path.join(folder_path, f'dist.npy'), dist)\n",
    "            # np.save(os.path.join(folder_path, f'attack.npy'), attack)\n",
    "\n",
    "                print('=' * 100)\n",
    "                print(f\"[Epoch {epoch + 1}] \"\n",
    "                    f\"Time: {time.time() - epoch_time:.2f}s | \"\n",
    "                    f\"Steps: {train_steps} | \"\n",
    "                    f\"Train Loss: {train_loss_avg:.8f} | \"\n",
    "                    f\"Val Loss: {valid_loss:.8f}\")\n",
    "\n",
    "                history['validation_loss'].append(valid_loss)\n",
    "\n",
    "                ckp.check(epoch=epoch + 1, model=self.model, score=valid_loss, lr=model_optim.param_groups[0]['lr'])\n",
    "\n",
    "                if early_stopping.validate(valid_loss):\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "            else:\n",
    "                print('=' * 100)\n",
    "                print(f\"[Epoch {epoch + 1}] \"\n",
    "                  f\"Time: {time.time() - epoch_time:.2f}s | \"\n",
    "                  f\"Steps: {train_steps} | \"\n",
    "                  f\"Train Loss: {train_loss_avg:.8f}\")\n",
    "                \n",
    "                # train loss 기준 체크\n",
    "                ckp.check(epoch=epoch + 1, model=self.model, score=train_loss_avg, lr=model_optim.param_groups[0]['lr'])\n",
    "                \n",
    "                if early_stopping.validate(train_loss_avg):\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "                \n",
    "            history['train_loss'].append(train_loss_avg)\n",
    "            # adjust_learning_rate(model_optim, epoch + 1, self.params)\n",
    "        \n",
    "        best_model_path = os.path.join(self.savedir, f'{ckp.best_epoch}.pth')\n",
    "        checkpoint = torch.load(best_model_path, weights_only=False)\n",
    "        \n",
    "        if isinstance(self.model, nn.DataParallel):\n",
    "            # self.model.module.load_state_dict(torch.load(best_model_path)['weight'])\n",
    "            self.model.module.load_state_dict(checkpoint['weight'])\n",
    "        else:\n",
    "            # self.model.load_state_dict(torch.load(best_model_path)['weight'])\n",
    "            self.model.load_state_dict(checkpoint['weight'])\n",
    "\n",
    "        return history\n",
    "\n",
    "\n",
    "    def test(self, valid_loader, test_loader, alpha=.5, beta=.5):\n",
    "        \"\"\"\n",
    "        test\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_loader\n",
    "            given : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                input time-series data\n",
    "            ts : ndarray (shape=(batch size, window size))\n",
    "                input timestamp\n",
    "            answer : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                target time-series data\n",
    "                If model_type is prediction, window size is 1\n",
    "            attack : ndarray\n",
    "            attack labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.args.resume is not None and self.args.train is not True:\n",
    "            print(f'resume version{self.args.resume}')\n",
    "            weights, start_epoch, self.args.lr, best_metrics = load_model(resume=self.args.resume,\n",
    "                                                                          logdir=self.savedir)\n",
    "            if isinstance(self.model, nn.DataParallel):\n",
    "                self.model.module.load_state_dict(weights)\n",
    "            else:\n",
    "                self.model.load_state_dict(weights)\n",
    "\n",
    "        # dist, attack, pred = [], [], []\n",
    "        dist, pred = [], []\n",
    "        history = dict()\n",
    "        criterion = self._select_criterion()\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():      \n",
    "            for batch_idx, batch in enumerate(test_loader):\n",
    "                batch_x = batch['given'].float().to(self.device)\n",
    "                batch_y = batch['answer'].float().to(self.device)\n",
    "                # batch_attack = batch['attack'].reshape(-1, batch['attack'].shape[-1]).numpy()\n",
    "\n",
    "                if self.args.model in ['VTTSAT', 'VTTPAT']:\n",
    "                    predictions, _ = self.model(batch_x)\n",
    "                else:\n",
    "                    predictions = self.model(batch_x)\n",
    "\n",
    "                score = criterion(predictions, batch_y).cpu().detach().numpy()\n",
    "                pred.append(predictions.cpu().detach().numpy())\n",
    "                dist.append(np.mean(score, axis=2))\n",
    "                # attack.append(batch_attack)\n",
    "\n",
    "        dist = np.concatenate(dist).flatten()\n",
    "        # attack = np.concatenate(attack).flatten()\n",
    "        pred = np.concatenate(pred)\n",
    "\n",
    "        # # score\n",
    "        # scores = dist.copy()\n",
    "        # K = [0, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "        # f1_values = []\n",
    "\n",
    "        # print(f'Threshold start: {np.percentile(scores, 90):.4f} end: {np.percentile(scores, 99):.4f}')\n",
    "\n",
    "        # for k in K:\n",
    "        #     scores = dist.copy()\n",
    "        #     [f1, precision, recall, _, _, _, _, roc_auc, _, _], threshold = bf_search(scores, attack,\n",
    "        #                                                                         start=np.percentile(scores, 50),\n",
    "        #                                                                         end=np.percentile(scores, 99),\n",
    "        #                                                                         step_num=1000,\n",
    "        #                                                                         K=k,\n",
    "        #                                                                         verbose=False)\n",
    "\n",
    "        #     f1_values.append(f1)\n",
    "        #     print(f\"K: {k} precision: {precision:.4f} recall: {recall:.4f} f1: {f1:.4f} AUROC: {roc_auc:.4f}\")\n",
    "        #     history.setdefault(f'precision_{k}', []).append(precision)\n",
    "        #     history.setdefault(f'recall_{k}', []).append(recall)\n",
    "        #     history.setdefault(f'f1_{k}', []).append(f1)\n",
    "        #     history.setdefault(f'roc_auc', []).append(roc_auc)\n",
    "\n",
    "        # auc = sum(0.5 * (f1_values[i] + f1_values[i + 1]) * (K[i + 1] - K[i]) for i in range(len(K) - 1)) / 100\n",
    "        # print(f'PA%K AUC: {auc}')\n",
    "\n",
    "        # visual = check_graph(dist, attack, piece=4, threshold=threshold)\n",
    "        # figure_path = os.path.join(self.savedir, 'fig')\n",
    "        # os.makedirs(figure_path, exist_ok=True)\n",
    "        # visual.savefig(os.path.join(figure_path, f'whole.png'))\n",
    "\n",
    "        # result save\n",
    "        folder_path = os.path.join(self.savedir, 'results')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        np.save(os.path.join(folder_path, f'dist.npy'), dist)\n",
    "        # np.save(os.path.join(folder_path, f'attack.npy'), attack)\n",
    "        np.save(os.path.join(folder_path, f'pred.npy'), pred)\n",
    "\n",
    "        return history\n",
    "\n",
    "    def inference(self, test_loader, epoch, alpha=.5, beta=.5):\n",
    "        \"\"\"\n",
    "        inference\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_loader\n",
    "            given : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                input time-series data\n",
    "            ts : ndarray (shape=(batch size, window size))\n",
    "                input timestamp\n",
    "            answer : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                target time-series data\n",
    "                If model_type is prediction, window size is 1\n",
    "            attack : ndarray\n",
    "            attack labels\n",
    "        epoch : int\n",
    "            train epoch\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        dist = []\n",
    "        attack = []\n",
    "        criterion = self._select_criterion()\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(test_loader):\n",
    "                batch_x = batch['given'].float().to(self.device)\n",
    "                batch_y = batch['answer'].float().to(self.device)\n",
    "\n",
    "                if self.args.model in ['VTTSAT', 'VTTPAT']:\n",
    "                    predictions, _ = self.model.forward(batch_x)\n",
    "                    score = criterion(predictions, batch_y).cpu().detach().numpy()\n",
    "                    dist.append(np.mean(score, axis=2))\n",
    "                    \n",
    "                else:\n",
    "                    predictions = self.model.forward(batch_x)\n",
    "                    score = criterion(predictions, batch_y).cpu().detach().numpy()\n",
    "                    dist.append(np.mean(score, axis=2))\n",
    "\n",
    "                attack.append(batch['attack'].reshape(-1, batch['attack'].shape[-1]).numpy())\n",
    "\n",
    "        dist = np.concatenate(dist).flatten()\n",
    "        attack = np.concatenate(attack).flatten()\n",
    "\n",
    "        return dist, attack\n",
    "\n",
    "\n",
    "    def interpret(self, test_loader):\n",
    "        \"\"\"\n",
    "        interpret\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_loader\n",
    "            given : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                input time-series data\n",
    "            ts : ndarray (shape=(batch size, window size))\n",
    "                input timestamp\n",
    "            answer : torch.Tensor (shape=(batch size, window size, num of features))\n",
    "                target time-series data\n",
    "                If model_type is prediction, window size is 1\n",
    "            attack : ndarray\n",
    "            attack labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        if self.args.resume is not None:\n",
    "            print(f'resume version{self.args.resume}')\n",
    "            weights, start_epoch, self.args.lr, best_metrics = load_model(resume=self.args.resume,\n",
    "                                                                          logdir=self.savedir)\n",
    "            if isinstance(self.model, nn.DataParallel):\n",
    "                self.model.module.load_state_dict(weights)\n",
    "            else:\n",
    "                self.model.load_state_dict(weights)\n",
    "\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "        hist = dict()\n",
    "        \n",
    "        scores, labels, tss, vattns, tattns = [], [], [], [], []\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(test_loader):\n",
    "                batch_x = batch['given'].float().to(self.device)\n",
    "                batch_y = batch['answer'].float().to(self.device)\n",
    "\n",
    "                predictions, [prior_vattn, prior_tattn] = self.model(batch_x, use_attn=True)\n",
    "                _, [post_vattn, post_tattn] = self.model(predictions, use_attn=True)\n",
    "                \n",
    "                score = criterion(predictions, batch_y).cpu().detach().numpy()\n",
    "                scores.append(score)\n",
    "                labels.append(label)\n",
    "                tss.append(batch_idx)\n",
    "\n",
    "                vattns.append([\n",
    "                    [vt.cpu().detach().numpy() for vt in prior_vattn],\n",
    "                    [vt.cpu().detach().numpy() for vt in post_vattn]\n",
    "                ])\n",
    "                tattns.append([\n",
    "                    [tt.cpu().detach().numpy() for tt in prior_tattn],\n",
    "                    [tt.cpu().detach().numpy() for tt in post_tattn]\n",
    "                ])\n",
    "\n",
    "        return scores, labels, tss, vattns, tattns\n",
    "    \n",
    "\n",
    "    def inference_unlabeled(self, test_loader):\n",
    "        \"\"\"\n",
    "        Inference for unlabeled WaferDataset:\n",
    "        - Saves prediction, actual, error (with masking), and wafer metadata to HDF5\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        actuals = []\n",
    "        dist_per_feature = []\n",
    "\n",
    "        lotids = []\n",
    "        wafer_numbers = []\n",
    "        step_nums = []\n",
    "        masks=[]\n",
    "\n",
    "        criterion = self._select_criterion()  # 반드시 reduction='none'으로 설정되어 있어야 함\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            with tqdm(total=len(test_loader), desc=\"Inference (per-feature + metadata)\", leave=True) as pbar:\n",
    "                for batch in test_loader:\n",
    "                    batch_x = batch['given'].float().to(self.device)        # (B, T, D)\n",
    "                    batch_y = batch['answer'].float().to(self.device)       # (B, T, D)\n",
    "                    batch_mask = batch['mask'].float().to(self.device)      # (B, T)\n",
    "\n",
    "                    # Model forward with mask (if VTTSAT or VTTPAT)\n",
    "                    if self.args.model in ['VTTSAT', 'VTTPAT']:\n",
    "                        predictions, _ = self.model(batch_x, mask=batch_mask)\n",
    "                    else:\n",
    "                        predictions = self.model(batch_x)\n",
    "\n",
    "                    # Loss 계산 (reconstruction error), masking 적용\n",
    "                    raw_loss = criterion(predictions, batch_y)             # (B, T, D)\n",
    "                    masked_loss = raw_loss * batch_mask.unsqueeze(-1)      # (B, T, D)\n",
    "                    dist_per_feature.append(masked_loss.cpu().numpy())\n",
    "\n",
    "                    # 결과 저장\n",
    "                    preds.append(predictions.cpu().numpy())\n",
    "                    actuals.append(batch_y.cpu().numpy())\n",
    "                    lotids.extend(batch['lotid'])\n",
    "                    wafer_numbers.extend(batch['wafer_number'])\n",
    "                    step_nums.extend(batch['step_num'])\n",
    "                    masks.extend(batch['mask'])\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "        preds = np.concatenate(preds, axis=0)               # (N, T, D)\n",
    "        actuals = np.concatenate(actuals, axis=0)           # (N, T, D)\n",
    "        dist_per_feature = np.concatenate(dist_per_feature, axis=0)  # (N, T, D)\n",
    "\n",
    "        lotids = np.array(lotids, dtype='S')                # str → byte로 저장\n",
    "        wafer_numbers = np.array(wafer_numbers, dtype='S')\n",
    "        step_nums = np.array(step_nums)\n",
    "        masks = np.array(masks) \n",
    "        \n",
    "        # 저장\n",
    "        folder_path = os.path.join(self.savedir, 'results')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        save_path = os.path.join(folder_path, 'inference_result_with_metadata.h5')\n",
    "\n",
    "        with h5py.File(save_path, 'w') as f:\n",
    "            f.create_dataset('actual', data=actuals, compression='gzip')\n",
    "            f.create_dataset('pred', data=preds, compression='gzip')\n",
    "            f.create_dataset('dist_per_window_per_features', data=dist_per_feature, compression='gzip')\n",
    "            f.create_dataset('lotid', data=lotids)\n",
    "            f.create_dataset('wafer_number', data=wafer_numbers)\n",
    "            f.create_dataset('step_num', data=step_nums)\n",
    "            f.create_dataset('mask', data=np.concatenate(masks, axis=0))\n",
    "\n",
    "        print(f\"[✓] HDF5 with metadata saved to: {save_path}\")\n",
    "        return preds, actuals, dist_per_feature, lotids, wafer_numbers, step_nums\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd5298",
   "metadata": {},
   "source": [
    "### STEP 9. XAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33fc039",
   "metadata": {},
   "source": [
    "<img src=\"../image/XAI.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcl\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.utils import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae052b",
   "metadata": {},
   "source": [
    "- 모델 체크포인트 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.resume = 5\n",
    "model = build_model(args, model_params, savedir)\n",
    "weights, _, _, _ = load_model(resume=args.resume,\n",
    "                              logdir=savedir)\n",
    "model.model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_by_uid(preds, actuals, lotids, wafer_numbers, masks, target_uid):\n",
    "    \"\"\"\n",
    "    주어진 UID에 해당하는 window들을 반환 (입력 데이터와 mask 모두)\n",
    "    \n",
    "    Args:\n",
    "        preds, actuals: (N, T, D)\n",
    "        masks: (N, T)\n",
    "        lotids, wafer_numbers: 리스트 또는 배열\n",
    "        target_uid: 'lotid-wafer_number' 형식의 문자열\n",
    "\n",
    "    Returns:\n",
    "        input_windows: torch.Tensor of shape (B, T, D)\n",
    "        input_masks: torch.Tensor of shape (B, T)\n",
    "    \"\"\"\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "    indices = np.where(unique_ids == target_uid)[0]\n",
    "    if len(indices) == 0:\n",
    "        raise ValueError(f\"UID '{target_uid}'에 해당하는 window 없음\")\n",
    "\n",
    "    input_windows = actuals[indices]  # 예측 대상은 actual (input)\n",
    "    input_masks = masks[indices]\n",
    "\n",
    "    return torch.tensor(input_windows).float(), torch.tensor(input_masks).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fede97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff_attns(prior, post, mask=None):\n",
    "    \"\"\"\n",
    "    prior, post: shape (L, T, H, D, D)\n",
    "    mask: shape (T,) or (1, T), where 1 indicates valid time step\n",
    "\n",
    "    Returns:\n",
    "        diff: shape (D, D) – 평균 diff (마스킹 적용됨)\n",
    "    \"\"\"\n",
    "    diff = np.abs(post - prior)  # (L, T, H, D, D)\n",
    "\n",
    "    if mask is not None:\n",
    "        if mask.ndim == 2:\n",
    "            mask = mask[0]  # shape: (T,)\n",
    "\n",
    "        # broadcast mask to (L, T, H, D, D)\n",
    "        mask_broadcast = mask[None, :, None, None, None]  # (1, T, 1, 1, 1)\n",
    "        diff = np.where(mask_broadcast, diff, np.nan)     # 마스킹된 부분은 NaN\n",
    "\n",
    "        diff = np.nanmean(diff, axis=(0, 1, 2))            # NaN 제외 평균\n",
    "    else:\n",
    "        diff = np.mean(diff, axis=(0, 1, 2))               # 전체 평균\n",
    "    return diff  # shape: (D, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c313c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_uid = highlight_uids[\"Mat_Irms\"][\"Right-Top\"][0]  # 예시: 첫 번째 UID\n",
    "input_tensor, mask_tensor = get_input_by_uid(preds, actuals, lotids, wafer_numbers, masks, target_uid)\n",
    "\n",
    "model.model.eval()\n",
    "with torch.no_grad():\n",
    "    input_prior_pred, [input_prior_vattn, input_prior_tattn] = model.model(input_tensor.to(device), use_attn=True)\n",
    "    input_post_pred, [input_post_vattn, input_post_tattn] = model.model(input_prior_pred, use_attn=True)\n",
    "\n",
    "normal_prior_score = model._select_criterion()(input_tensor.to(device), input_prior_pred).cpu().detach().numpy().mean()\n",
    "normal_post_score = model._select_criterion()(input_prior_pred, input_post_pred).cpu().detach().numpy().mean()\n",
    "print(f'Prior score: {normal_prior_score:.6f}, Post score: {normal_post_score:.6f}')\n",
    "\n",
    "input_prior_vattn = input_prior_vattn.cpu().detach().numpy()\n",
    "input_post_vattn = input_post_vattn.cpu().detach().numpy()\n",
    "\n",
    "input_diff = calc_diff_attns(input_prior_vattn, input_post_vattn, mask_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed5470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors as mcl\n",
    "from collections import defaultdict\n",
    "def save_attn_diff_per_wafer_train(trainloader, model, feature_names, save_root='attn_diff_results_train', device='cuda'):\n",
    "    \"\"\"\n",
    "    train셋의 웨이퍼들에 대한 attention diff heatmap 저장\n",
    "    \"\"\"\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    model.model.eval()\n",
    "\n",
    "    # UID별 window들을 모음\n",
    "    uid_to_windows = defaultdict(list)\n",
    "\n",
    "    # window 단위 → UID 단위로 수집\n",
    "    for i in range(len(trainloader.dataset)):\n",
    "        sample = trainloader.dataset[i]\n",
    "        lotid = sample['lotid']\n",
    "        wafer = sample['wafer_number']\n",
    "        mask = sample['mask']\n",
    "        uid = f\"{lotid}-{wafer}\"\n",
    "\n",
    "\n",
    "        uid_to_windows[uid].append(sample['given'])\n",
    "\n",
    "    for uid, window_list in uid_to_windows.items():\n",
    "        try:\n",
    "            input_tensor = torch.tensor(np.stack(window_list)).float().to(device)  # (B, W, D)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prior_pred, [prior_vattn, _] = model.model(input_tensor, use_attn=True)\n",
    "                post_pred, [post_vattn, _] = model.model(prior_pred, use_attn=True)\n",
    "\n",
    "            prior_vattn = prior_vattn.cpu().detach().numpy()\n",
    "            post_vattn = post_vattn.cpu().detach().numpy()\n",
    "            diff = calc_diff_attns(prior_vattn, post_vattn, mask)  # (D, D)\n",
    "\n",
    "            # 시각화 및 저장\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            h, s, v = 24, 0.99, 0.99\n",
    "            colors = [\n",
    "                mcl.hsv_to_rgb((h/360, 0, v)),\n",
    "                mcl.hsv_to_rgb((h/360, 0.5, v)),\n",
    "                mcl.hsv_to_rgb((h/360, 1, v))\n",
    "            ]\n",
    "            cmap = LinearSegmentedColormap.from_list('my_cmap', colors, gamma=3)\n",
    "\n",
    "            ax = sns.heatmap(\n",
    "                diff,\n",
    "                cmap=cmap,\n",
    "                annot=True,\n",
    "                fmt=\".4f\",\n",
    "                annot_kws={\"size\": 8},\n",
    "                xticklabels=feature_names,\n",
    "                yticklabels=feature_names,\n",
    "                cbar=True\n",
    "            )\n",
    "\n",
    "            ax.xaxis.tick_top()\n",
    "            plt.xticks(rotation=90, ha='center', fontsize=10)\n",
    "            plt.yticks(rotation=0, va='center', fontsize=10)\n",
    "            plt.title(f'Change of Correlations: {uid}', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            save_path = os.path.join(save_root, f'{uid}_attn_diff.png')\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"[저장 완료] {save_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[에러] {uid} 처리 중 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_attn_diff_per_wafer_train(\n",
    "    trainloader=trainloader,\n",
    "    model=model,\n",
    "    feature_names=feature_names,\n",
    "    save_root='./logs/vtt_all_step/VTTSAT/version5/plots/attn_diff_results_train',\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e619c48",
   "metadata": {},
   "source": [
    "# 250521 피드백 후 자료만들기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_top_bottom_wafers_per_sensor(score_df, top_k=10, draw_plot=True, save_dir=None):\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    sensor_columns = [col for col in score_df.columns if col not in ['step', 'unique_id']]\n",
    "    result = {}\n",
    "    result_rows = []\n",
    "\n",
    "    for sensor in sensor_columns:\n",
    "        df_sorted = score_df[['unique_id', sensor]].sort_values(by=sensor)\n",
    "        bottom_rows = df_sorted.head(top_k)\n",
    "        top_rows = df_sorted.tail(top_k)\n",
    "\n",
    "        bottom_ids = bottom_rows['unique_id'].tolist()\n",
    "        top_ids = top_rows['unique_id'].tolist()\n",
    "\n",
    "        result[sensor] = {\n",
    "            'bottom': bottom_ids,\n",
    "            'top': top_ids,\n",
    "        }\n",
    "\n",
    "        # 🔴 bottom k 추가\n",
    "        for i in range(len(bottom_rows)):\n",
    "            result_rows.append({\n",
    "                'sensor': sensor,\n",
    "                'rank_type': 'bottom',\n",
    "                'unique_id': bottom_rows.iloc[i]['unique_id'],\n",
    "                'score': bottom_rows.iloc[i][sensor]\n",
    "            })\n",
    "\n",
    "        # 🔵 top k 추가\n",
    "        for i in range(len(top_rows)):\n",
    "            result_rows.append({\n",
    "                'sensor': sensor,\n",
    "                'rank_type': 'top',\n",
    "                'unique_id': top_rows.iloc[i]['unique_id'],\n",
    "                'score': top_rows.iloc[i][sensor]\n",
    "            })\n",
    "\n",
    "        if draw_plot:\n",
    "            plt.figure(figsize=(6, 2.5))\n",
    "\n",
    "            others_mask = ~score_df['unique_id'].isin(top_ids + bottom_ids)\n",
    "            sns.stripplot(x=score_df[others_mask][sensor], color='gray', size=2.5, jitter=0.25, label='others')\n",
    "            sns.stripplot(x=bottom_rows[sensor], color='red', size=3, jitter=0.25, label='Lowest 10')\n",
    "            sns.stripplot(x=top_rows[sensor], color='blue', size=3, jitter=0.25, label='Highest 10')\n",
    "\n",
    "\n",
    "            plt.title(sensor)\n",
    "            plt.xlabel(\"VTT Score\")\n",
    "            plt.yticks([])\n",
    "            plt.legend(loc='upper right', fontsize=8)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if save_dir:\n",
    "                plt.savefig(f\"{save_dir}/{sensor}_score_dist.png\", dpi=150)\n",
    "            else:\n",
    "                plt.show()\n",
    "\n",
    "    if save_dir:\n",
    "        df_result = pd.DataFrame(result_rows)\n",
    "        df_result.to_csv(os.path.join(save_dir, 'highest_lowest_results.csv'), index=False)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "top_bottom_ids_per_sensor = get_top_bottom_wafers_per_sensor(\n",
    "    vtt_all_scores_df,\n",
    "    top_k=10,\n",
    "    draw_plot=True,\n",
    "    save_dir=\"./logs/vtt_all_step/VTTSAT/version5/plots/score_dist\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9bb2bd",
   "metadata": {},
   "source": [
    "### reference, highest, lowest 실제값 시계열 plot 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "P_FG_ch1 = pd.read_parquet(\"drystrip_dataset/bigger_train_df.parquet\")\n",
    "interested_sensors = ['APC_Position', 'APC_Pressure', 'Gas1_Monitor', 'Gas6_Monitor', 'Mat_Irms', 'Mat_Phase','Mat_Vrms',\n",
    "                      'Mat_VC1_Position', 'Mat_VC2_Position', 'SourcePwr_Read', 'Temp', 'Wall_Temp_Monitor']\n",
    "\n",
    "filterd_df = pd.concat([P_FG_ch1[['time', 'lotid', 'wafer_number', 'Recipe_Step_Num']],P_FG_ch1[interested_sensors]], axis=1)\n",
    "filterd_df = filterd_df.sort_values(by=[\"lotid\", \"wafer_number\", \"time\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11614ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = list(filterd_df.groupby(['lotid', 'wafer_number'])) \n",
    "normal_groups = [group for group in grouped]\n",
    "train_df = pd.concat([group[1] for group in normal_groups])\n",
    "train_df_test = train_df.drop(columns='time')\n",
    "train_df_test\n",
    "train_df.groupby(['lotid','wafer_number','Recipe_Step_Num'])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_data_combined = train_df.iloc[:,4:]\n",
    "train_scaled = scaler.fit_transform(train_data_combined)\n",
    "train_scaled = pd.concat([train_df.iloc[:,:4], pd.DataFrame(train_scaled, columns=interested_sensors)], axis=1)\n",
    "train_scaled = train_scaled.drop(columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263bd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_lowest_bottom_actuals_with_reference(\n",
    "    actuals, lotids, wafer_numbers, feature_names,\n",
    "    highest_lowest_df, reference_df,\n",
    "    mask=None,\n",
    "    output_dir=\"top_bottom_overlay_plots\",\n",
    "    ref_max_count=100\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "\n",
    "    D = actuals.shape[2]\n",
    "    highest_lowest_df = highest_lowest_df.copy()\n",
    "\n",
    "    for sensor in highest_lowest_df['sensor'].unique():\n",
    "        if sensor not in feature_names:\n",
    "            continue\n",
    "\n",
    "        sensor_idx = feature_names.index(sensor)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        ax.set_title(f\"{sensor} | Lowest vs Highest actuals\", fontsize=13)\n",
    "\n",
    "        # reference\n",
    "        if reference_df is not None and sensor in reference_df.columns:\n",
    "            ref_grouped = reference_df.groupby(['lotid', 'wafer_number'])\n",
    "            ref_keys = random.sample(list(ref_grouped.groups.keys()), min(ref_max_count, len(ref_grouped)))\n",
    "            for key in ref_keys:\n",
    "                ref_series = ref_grouped.get_group(key).reset_index(drop=True)[sensor].values\n",
    "                ax.plot(ref_series, color='#999999', alpha=1.0, linewidth=1.0,\n",
    "                        label='Reference' if key == ref_keys[0] else None)\n",
    "\n",
    "        # top 10\n",
    "        top_ids = highest_lowest_df[(highest_lowest_df['sensor'] == sensor) & (highest_lowest_df['rank_type'] == 'top')]['unique_id']\n",
    "        for i, uid in enumerate(top_ids):\n",
    "            idxs = np.where(unique_ids == uid)[0]\n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            idx = idxs[0]\n",
    "\n",
    "            if mask is not None:\n",
    "                valid = mask[idx] == 1\n",
    "                actual_seq = actuals[idx, valid, sensor_idx]\n",
    "            else:\n",
    "                actual_seq = actuals[idx, :, sensor_idx]\n",
    "\n",
    "            ax.plot(actual_seq, color='blue', alpha=0.6, linewidth=0.8,\n",
    "                    label='Highest 10 Actual' if i == 0 else None)\n",
    "\n",
    "        # bottom 10\n",
    "        bottom_ids = highest_lowest_df[(highest_lowest_df['sensor'] == sensor) & (highest_lowest_df['rank_type'] == 'bottom')]['unique_id']\n",
    "        for i, uid in enumerate(bottom_ids):\n",
    "            idxs = np.where(unique_ids == uid)[0]\n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            idx = idxs[0]\n",
    "\n",
    "            if mask is not None:\n",
    "                valid = mask[idx] == 1\n",
    "                actual_seq = actuals[idx, valid, sensor_idx]\n",
    "            else:\n",
    "                actual_seq = actuals[idx, :, sensor_idx]\n",
    "\n",
    "            ax.plot(actual_seq, color='red', alpha=0.6, linewidth=0.8,\n",
    "                    label='Lowest 10 Actual' if i == 0 else None)\n",
    "\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Sensor Value')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        save_path = os.path.join(output_dir, f'{sensor}_highest_lowest_actual_overlay.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    return f\"✅ 저장 완료: {output_dir}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_lowest_df = pd.read_csv('./logs/vtt_all_step/VTTSAT/version5/plots/highest_lowest_results.csv')\n",
    "\n",
    "highest_lowest_bottom_actuals_with_reference(\n",
    "    actuals=actuals,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    feature_names=feature_names,\n",
    "    highest_lowest_df=highest_lowest_df,\n",
    "    reference_df=train_scaled,\n",
    "    mask=masks,\n",
    "    output_dir=\"./logs/vtt_all_step/VTTSAT/version5/plots/highest_lowest_overlay\",\n",
    "    ref_max_count=1163\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457dd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def highest_lowest_bottom_actuals_with_reference_custom_single(\n",
    "    actuals, lotids, wafer_numbers, feature_names,\n",
    "    highest_lowest_df, reference_df,\n",
    "    mask=None,\n",
    "    output_dir=\"custom_overlay_plots_single\",\n",
    "    ref_max_count=100\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "\n",
    "    D = actuals.shape[2]\n",
    "    highest_lowest_df = highest_lowest_df.copy()\n",
    "\n",
    "    sensor_groups = {\n",
    "        'APC_Position': ['APC_Position', 'APC_Pressure', 'Mat_Irms', 'Mat_VC1_Position'],\n",
    "        'APC_Pressure': ['APC_Pressure'],\n",
    "        'Gas1_Monitor': ['Gas1_Monitor', 'Wall_Temp_Monitor'],\n",
    "        'Gas6_Monitor': ['Gas6_Monitor', 'Mat_Irms', 'Mat_VC2_Position'],\n",
    "        'Mat_Irms': ['Mat_Irms', 'APC_Pressure', 'Mat_Vrms', 'Wall_Temp_Monitor'],\n",
    "        'Mat_Phase': ['Mat_Phase', 'Mat_VC2_Position'],\n",
    "        'Wall_Temp_Monitor': ['Wall_Temp_Monitor'],\n",
    "        'Temp': ['Temp','Wall_Temp_Monitor', 'Mat_Irms'],\n",
    "        'SourcePwr_Read': ['APC_Pressure', 'SourcePwr_Read',  'Temp'],\n",
    "        'Mat_Vrms': ['APC_Pressure', 'Mat_Vrms',  'Mat_VC1_Position', 'Temp' ],\n",
    "        'Mat_VC2_Position': ['Mat_VC2_Position', 'Mat_Vrms','Wall_Temp_Monitor'],\n",
    "        'Mat_VC1_Position': ['Mat_VC1_Position', 'APC_Pressure', 'Mat_Phase', 'Mat_VC2_Position', 'Temp', 'Wall_Temp_Monitor'],\n",
    "    }\n",
    "\n",
    "    for key_sensor, related_sensors in sensor_groups.items():\n",
    "        fig, axes = plt.subplots(len(related_sensors), 1, figsize=(10, 3 * len(related_sensors)), sharex=True)\n",
    "\n",
    "        if len(related_sensors) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, sensor in zip(axes, related_sensors):\n",
    "            if sensor not in feature_names:\n",
    "                continue\n",
    "\n",
    "            sensor_idx = feature_names.index(sensor)\n",
    "\n",
    "            # reference\n",
    "            if reference_df is not None and sensor in reference_df.columns:\n",
    "                ref_grouped = reference_df.groupby(['lotid', 'wafer_number'])\n",
    "                ref_keys = random.sample(list(ref_grouped.groups.keys()), min(ref_max_count, len(ref_grouped)))\n",
    "                for key in ref_keys:\n",
    "                    ref_series = ref_grouped.get_group(key).reset_index(drop=True)[sensor].values\n",
    "                    ax.plot(ref_series, color='#999999', alpha=0.5, linewidth=1.0,\n",
    "                            label='Reference' if key == ref_keys[0] else None)\n",
    "\n",
    "            # Highest (1개만)\n",
    "            top_ids = highest_lowest_df[\n",
    "                (highest_lowest_df['sensor'] == key_sensor) &\n",
    "                (highest_lowest_df['rank_type'] == 'top')\n",
    "            ]['unique_id'].values[:1]\n",
    "\n",
    "            for uid in top_ids:\n",
    "                idxs = np.where(unique_ids == uid)[0]\n",
    "                if len(idxs) == 0:\n",
    "                    continue\n",
    "                idx = idxs[0]\n",
    "                if mask is not None:\n",
    "                    valid = mask[idx] == 1\n",
    "                    actual_seq = actuals[idx, valid, sensor_idx]\n",
    "                else:\n",
    "                    actual_seq = actuals[idx, :, sensor_idx]\n",
    "\n",
    "                ax.plot(actual_seq, color='blue', alpha=0.6, linewidth=1.2,\n",
    "                        label='Highest')\n",
    "\n",
    "            # Lowest (1개만)\n",
    "            bottom_ids = highest_lowest_df[\n",
    "                (highest_lowest_df['sensor'] == key_sensor) &\n",
    "                (highest_lowest_df['rank_type'] == 'bottom')\n",
    "            ]['unique_id'].values[:1]\n",
    "\n",
    "            for uid in bottom_ids:\n",
    "                idxs = np.where(unique_ids == uid)[0]\n",
    "                if len(idxs) == 0:\n",
    "                    continue\n",
    "                idx = idxs[0]\n",
    "                if mask is not None:\n",
    "                    valid = mask[idx] == 1\n",
    "                    actual_seq = actuals[idx, valid, sensor_idx]\n",
    "                else:\n",
    "                    actual_seq = actuals[idx, :, sensor_idx]\n",
    "\n",
    "                ax.plot(actual_seq, color='red', alpha=0.6, linewidth=1.2,\n",
    "                        label='Lowest')\n",
    "\n",
    "            ax.set_ylabel(sensor)\n",
    "            ax.legend(fontsize=7)\n",
    "            ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        axes[-1].set_xlabel('Time')\n",
    "        fig.suptitle(f\"{key_sensor} | Highest vs Lowest\", fontsize=13)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        save_path = os.path.join(output_dir, f'{key_sensor}_context_overlay_single.png')\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    return f\"✅ 저장 완료: {output_dir}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2297bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_lowest_bottom_actuals_with_reference_custom_single(\n",
    "    actuals=actuals,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    feature_names=feature_names,\n",
    "    highest_lowest_df=highest_lowest_df,\n",
    "    reference_df=train_scaled,\n",
    "    mask=masks,\n",
    "    output_dir=\"./logs/vtt_all_step/VTTSAT/version5/plots/highest_lowest_context_overlay_single\",\n",
    "    ref_max_count=1163\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af7b25",
   "metadata": {},
   "source": [
    "### attention map difference 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e571ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_diff_top_bottom_per_sensor(\n",
    "    preds, actuals, lotids, wafer_numbers, masks,\n",
    "    highest_lowest_df, model, feature_names,\n",
    "    get_input_by_uid, calc_diff_attns,\n",
    "    save_root='attn_diff_top_bottom', device='cuda'\n",
    "):\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    model.model.eval()\n",
    "\n",
    "    lotids = np.array(lotids).astype(str)\n",
    "    wafer_numbers = np.array(wafer_numbers).astype(str)\n",
    "    unique_ids = np.char.add(lotids, np.char.add(\"-\", wafer_numbers))\n",
    "\n",
    "    for sensor in highest_lowest_df['sensor'].unique():\n",
    "        if sensor not in feature_names:\n",
    "            continue\n",
    "\n",
    "        sensor_df = highest_lowest_df[highest_lowest_df['sensor'] == sensor]\n",
    "        top_uid = sensor_df[sensor_df['rank_type'] == 'top']['unique_id'].values[0]\n",
    "        bottom_uid = sensor_df[sensor_df['rank_type'] == 'bottom']['unique_id'].values[0]\n",
    "        sensor_idx = feature_names.index(sensor)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        uids = {'Lowest': bottom_uid, 'Highest': top_uid}\n",
    "        diffs = {}\n",
    "\n",
    "        # 1. 먼저 두 diff 계산\n",
    "        for title, uid in uids.items():\n",
    "            try:\n",
    "                input_seq, input_mask = get_input_by_uid(\n",
    "                    preds, actuals, lotids, wafer_numbers, masks, uid\n",
    "                )\n",
    "                input_seq = input_seq.to(device)\n",
    "                mask_tensor = input_mask.cpu().numpy()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    prior_pred, [prior_vattn, _] = model.model(input_seq, use_attn=True)\n",
    "                    post_pred, [post_vattn, _] = model.model(prior_pred, use_attn=True)\n",
    "\n",
    "                prior_vattn = prior_vattn.cpu().detach().numpy()\n",
    "                post_vattn = post_vattn.cpu().detach().numpy()\n",
    "                diff = calc_diff_attns(prior_vattn, post_vattn, mask_tensor)\n",
    "                diffs[title] = diff\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[에러] {sensor} | {title} | {uid} 처리 실패: {e}\")\n",
    "                diffs[title] = None\n",
    "\n",
    "        # 2. min, max 계산\n",
    "        valid_diffs = [d for d in diffs.values() if d is not None]\n",
    "        if not valid_diffs:\n",
    "            continue\n",
    "\n",
    "        global_min = min(d.min() for d in valid_diffs)\n",
    "        global_max = max(d.max() for d in valid_diffs)\n",
    "\n",
    "        # 3. colormap 설정\n",
    "        h = 24\n",
    "        colors = [\n",
    "            mcl.hsv_to_rgb((h / 360, 0, 1)),\n",
    "            mcl.hsv_to_rgb((h / 360, 0.5, 1)),\n",
    "            mcl.hsv_to_rgb((h / 360, 1, 1))\n",
    "        ]\n",
    "        cmap = LinearSegmentedColormap.from_list('custom_cmap', colors, gamma=3)\n",
    "\n",
    "        # 4. 히트맵 시각화\n",
    "        for i, (title, diff) in enumerate(diffs.items()):\n",
    "            if diff is None:\n",
    "                continue\n",
    "\n",
    "            hm  = sns.heatmap(\n",
    "                diff,\n",
    "                cmap=cmap,\n",
    "                annot=True,\n",
    "                fmt=\".4f\",\n",
    "                annot_kws={\"size\": 4},\n",
    "                xticklabels=feature_names,\n",
    "                yticklabels=feature_names,\n",
    "                cbar=True,\n",
    "                ax=axes[i],\n",
    "                vmin=global_min,\n",
    "                vmax=global_max  # ✅ 고정 범위!\n",
    "            )\n",
    "\n",
    "            axes[i].set_title(f\"{title}\", fontsize=9)\n",
    "            axes[i].tick_params(axis='x', labelrotation=90, labelsize=6)\n",
    "            axes[i].tick_params(axis='y', labelsize=6)\n",
    "            colorbar = hm.collections[0].colorbar\n",
    "            colorbar.ax.tick_params(labelsize=5)  # ← 숫자 크기 8pt로 설정\n",
    "\n",
    "        plt.suptitle(f\"{sensor} | Attention Difference (Lowest vs Highest)\", fontsize=11)\n",
    "        plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "        save_path = os.path.join(save_root, f\"{sensor}_attn_diff_top_bottom.png\")\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    return f\"✅ 저장 완료: {save_root}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_diff_top_bottom_per_sensor(\n",
    "    preds=preds,\n",
    "    actuals=actuals,\n",
    "    lotids=lotids,\n",
    "    wafer_numbers=wafer_numbers,\n",
    "    masks=masks,\n",
    "    highest_lowest_df=highest_lowest_df,\n",
    "    model=model,\n",
    "    feature_names=feature_names,\n",
    "    get_input_by_uid=get_input_by_uid,\n",
    "    calc_diff_attns=calc_diff_attns,\n",
    "    save_root='./logs/vtt_all_step/VTTSAT/version5/plots/attn_diff_highest_lowest',\n",
    "    device='cuda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7656e",
   "metadata": {},
   "source": [
    "- 원본 데이터에서 추출한 attention map과 재구성된 데이터에서 추출한 attention map을 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079d9bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabf926d",
   "metadata": {},
   "source": [
    "### STEP 10. 명령어로 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f34b17",
   "metadata": {},
   "source": [
    "```\n",
    "python main.py \\\n",
    "--train \\\n",
    "--test \\\n",
    "--model VTTPAT \\\n",
    "--dataname SWaT \\\n",
    "--use_multi_gpu \\\n",
    "--devices 0,1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab46a7e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "VTT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "ko",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ko",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "344px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
