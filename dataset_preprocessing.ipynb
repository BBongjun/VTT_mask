{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet 파일 읽기\n",
    "P_FG_ch1 = pd.read_parquet(\"./drystrip_dataset/P_FG_60S_1_ref\")\n",
    "\n",
    "# 불러오고 싶은 컬럼 리스트 정의\n",
    "meta_colums = ['time', 'lotid', 'wafer_number', 'Recipe_Step_Num']\n",
    "interested_sensors = ['APC_Position', 'APC_Pressure', 'Gas1_Monitor', 'Gas6_Monitor', 'Mat_Irms', 'Mat_Phase','Mat_Vrms',\n",
    "                      'Mat_VC1_Position', 'Mat_VC2_Position', 'SourcePwr_Read', 'Temp', 'Wall_Temp_Monitor']\n",
    "\n",
    "filterd_df = pd.concat([P_FG_ch1[['time', 'lotid', 'wafer_number', 'Recipe_Step_Num']],P_FG_ch1[interested_sensors]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference 데이터 특정 컬럼만 불러오기\n",
    "P_FG_ch1_inf = pd.read_parquet(\"./drystrip_dataset/P_FG_60S_1_inf\", columns=meta_colums+interested_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.read_parquet(\"../drystrip_dataset/score_results.parquet\")\n",
    "score_df = score_df[score_df['sensor'].isin(interested_sensors)]\n",
    "\n",
    "# P_FG_60S_1 데이터만 필터링\n",
    "target_score_df = score_df[(score_df['recipe']=='P_FG_60S') & (score_df['stage']=='1')]\n",
    "\n",
    "target_score_df['lotid'] = target_score_df['fn'].apply(lambda x : '_'.join(x.split('_')[4:6]))\n",
    "target_score_df['wafer_number'] = target_score_df['fn'].apply(lambda x : int(x.split('_')[-1][:-5]))\n",
    "target_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inf_score_df = pd.merge(P_FG_ch1_inf, target_score_df, on=['lotid', 'wafer_number'], how='inner')\n",
    "unique_lot_wafer = merged_inf_score_df[['lotid', 'wafer_number']].drop_duplicates()\n",
    "print('매칭된 총 웨이퍼 수',unique_lot_wafer.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = P_FG_ch1_inf[\n",
    "    P_FG_ch1_inf.set_index(['lotid', 'wafer_number']).index.isin(\n",
    "        unique_lot_wafer.set_index(['lotid', 'wafer_number']).index\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reference 데이터 기간 늘리는 기준 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 그룹 기준: wafer 단위\n",
    "grouped = target_score_df.groupby(['lotid', 'wafer_number'])\n",
    "\n",
    "# 조건 만족하는 wafer 추출\n",
    "qualified_wafers = []\n",
    "\n",
    "mask = target_score_df.groupby(['lotid', 'wafer_number'])['sensor_score'].transform(lambda x: (x >= 95).all())\n",
    "qualified_df = target_score_df[mask]\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"모든 센서가 95점 이상인 웨이퍼 수: {qualified_df['fn'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "date_df = qualified_df.copy()\n",
    "date_df.drop_duplicates(subset=['lotid', 'wafer_number'], inplace=True)\n",
    "date_df['date'] = date_df['time'].dt.date\n",
    "date_df['date'].value_counts().sort_index().plot(kind='bar', figsize=(12,4))\n",
    "plt.title(\"Wafer Count by Date : All sensor score >= 95\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# ----------- 첫 번째: qualified_df 기반 bar plot (빨간색) -----------\n",
    "date_df1 = qualified_df.copy()\n",
    "date_df1.drop_duplicates(subset=['lotid', 'wafer_number'], inplace=True)\n",
    "date_df1['date'] = date_df1['time'].dt.date\n",
    "daily_counts1 = date_df1['date'].value_counts().sort_index()\n",
    "daily_counts1.index = pd.to_datetime(daily_counts1.index)\n",
    "\n",
    "# ----------- 두 번째: target_score_df 기반 line plot (파란색) -----------\n",
    "date_df2 = target_score_df.copy()\n",
    "date_df2.drop_duplicates(subset=['lotid', 'wafer_number'], inplace=True)\n",
    "date_df2['date'] = date_df2['time'].dt.date\n",
    "daily_counts2 = date_df2['date'].value_counts().sort_index()\n",
    "\n",
    "# 전체 날짜 범위 생성\n",
    "full_date_range = pd.date_range(start=daily_counts2.index.min(),\n",
    "                                end=daily_counts2.index.max())\n",
    "full_date_index = full_date_range.date\n",
    "\n",
    "# 두 집계 모두 누락 날짜 0으로 채우기\n",
    "daily_counts1_full = pd.Series(0, index=full_date_index)\n",
    "daily_counts2_full = pd.Series(0, index=full_date_index)\n",
    "daily_counts1_full.update(daily_counts1)\n",
    "daily_counts2_full.update(daily_counts2)\n",
    "daily_counts1_full.index = pd.to_datetime(daily_counts1_full.index)\n",
    "daily_counts2_full.index = pd.to_datetime(daily_counts2_full.index)\n",
    "\n",
    "# ----------- 시각화 -----------\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "# 빨간색 bar plot\n",
    "ax.plot(daily_counts1_full.index, daily_counts1_full.values, color='red', marker='o', markersize=2, linewidth=1, alpha=0.6, label='All sensor scores >=95')\n",
    "\n",
    "# 파란색 line plot\n",
    "ax.plot(daily_counts2_full.index, daily_counts2_full.values, color='blue', marker='o', markersize=2, linewidth=1, alpha=0.6, label='Total wafer')\n",
    "\n",
    "# x축 포맷\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.title(\"Wafer Count by Date\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건: qualified_df에 있는 lotid-wafer_number 조합\n",
    "qualified_pairs = qualified_df[['lotid', 'wafer_number']].drop_duplicates()\n",
    "\n",
    "# P_FG_ch1_inf에서 일치하는 wafer만 필터링\n",
    "matched_df = P_FG_ch1_inf.merge(qualified_pairs, on=['lotid', 'wafer_number'], how='inner')\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"매칭된 wafer 수: {matched_df[['lotid', 'wafer_number']].drop_duplicates().shape[0]}\")\n",
    "matched_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test_df에서 ~2023-12-31 23:59:59 까지의 데이터를 train(reference)에 추가하여 사용\n",
    "- test_df에서 2024-01-01 00:00:00 부터의 데이터를 test로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df['date'] = pd.to_datetime(date_df['date'])\n",
    "qualified_df = date_df[date_df['date'] < pd.Timestamp(\"2024-01-01 00:00:00\")]\n",
    "\n",
    "# 조건: qualified_df에 있는 lotid-wafer_number 조합\n",
    "qualified_pairs = qualified_df[['lotid', 'wafer_number']].drop_duplicates()\n",
    "\n",
    "# P_FG_ch1_inf에서 일치하는 wafer만 필터링\n",
    "matched_df = P_FG_ch1_inf.merge(qualified_pairs, on=['lotid', 'wafer_number'], how='inner')\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"매칭된 wafer 수: {matched_df[['lotid', 'wafer_number']].drop_duplicates().shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_train_df = pd.concat([filterd_df, matched_df], ignore_index=True)\n",
    "bigger_train_df['Lotid_wafer'] = bigger_train_df['lotid'] + '_' + bigger_train_df['wafer_number'].astype(str)\n",
    "ids = bigger_train_df['Lotid_wafer'].unique()\n",
    "np.save('big_ref_lotid_wafer_ids.npy', ids)\n",
    "bigger_train_df.to_parquet(\"bigger_train_df.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('총 reference 웨이퍼 수:',bigger_train_df[['lotid', 'wafer_number']].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.copy()\n",
    "test_df['time'] = pd.to_datetime(test_df['time'])\n",
    "\n",
    "# 필터링\n",
    "filtered_test_df = test_df[test_df['time'] >= pd.Timestamp(\"2024-01-01 00:00:00\", tz='UTC')]\n",
    "\n",
    "print('총 test 웨이퍼 수:',filtered_test_df[['lotid', 'wafer_number']].drop_duplicates().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웨이퍼 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_full_sequence(groups, output_folder, scaler):\n",
    "    \"\"\"\n",
    "    각 웨이퍼를 하나의 시계열로 저장 (VTT 전체 시계열 입력용)\n",
    "    - 입력(x): (T, D)\n",
    "    - step_num: (T,)\n",
    "    - 저장 파일 하나당 하나의 시계열 샘플 포함\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for (lotid, wafer_number), sensor in tqdm(groups, total=len(groups), desc=f\"Processing {output_folder}\"):\n",
    "        # 정렬 및 정규화\n",
    "        sensor = sensor.sort_values('time').reset_index(drop=True)\n",
    "        sensor_values = sensor.iloc[:, 4:].values  # → (T, D)\n",
    "        scaled_values = scaler.transform(sensor_values)\n",
    "        total_len = scaled_values.shape[0]\n",
    "\n",
    "        step_array = sensor['Recipe_Step_Num'].values  # (T,)\n",
    "\n",
    "        # 저장\n",
    "        file_path = os.path.join(output_folder, f\"{lotid}_{wafer_number}.h5\")\n",
    "        with h5py.File(file_path, 'w') as hf:\n",
    "            hf.create_dataset('data', data=scaled_values, compression='gzip')               # (T, D)\n",
    "            hf.create_dataset('labels', data=np.array([0]), compression='gzip')             # dummy label\n",
    "            hf.create_dataset('lotids', data=np.array([lotid]).astype('S'), compression='gzip')\n",
    "            hf.create_dataset('wafer_numbers', data=np.array([wafer_number]).astype('S'), compression='gzip')\n",
    "            hf.create_dataset('step_num', data=step_array, compression='gzip')              # (T,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(bigger_train_df.iloc[:, 4:].values.astype(float))\n",
    "\n",
    "# 웨이퍼 단위 groupby\n",
    "train_groups = bigger_train_df.groupby([\"lotid\", \"wafer_number\"])\n",
    "test_groups = filtered_test_df.groupby([\"lotid\", \"wafer_number\"])\n",
    "\n",
    "# 웨이퍼 단위로 시계열을 한 window로 저장\n",
    "process_and_save_full_sequence(train_groups, \"./data/all_step/train\", scaler)\n",
    "process_and_save_full_sequence(test_groups, \"./data/all_step/test\", scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bongjun_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
